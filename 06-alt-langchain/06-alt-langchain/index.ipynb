{
   "cells": [
      {
         "cell_type": "markdown",
         "metadata": {
            "jp-MarkdownHeadingCollapsed": true
         },
         "source": [
            "# 💡 这节课会带给你\n",
            "\n",
            "1. LangChain.js 和 LangSmith\n",
            "2. Semantic Kernel 的特点和基本用法\n",
            "3. 如何选择适合自己的 LLM 开发平台\n",
            "4. 如何给开源软件贡献代码\n",
            "\n",
            "开始上课！\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "# 大语言模型开发框架的价值是什么？\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "所有框架的核心价值，都是降低开发、维护成本。\n",
            "\n",
            "大语言模型开发框架的价值，是让开发者可以更方便地开发基于大语言模型的应用。主要提供两类帮助：\n",
            "\n",
            "1. 第三方能力抽象。比如 LLM、向量数据库、搜索引擎等\n",
            "2. 常用工具、方案封装\n",
            "\n",
            "<div class=\"alert alert-success\">\n",
            "<b>划重点：</b>选对了框架，事情成功一半。\n",
            "</div>\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "# LangChain vs. Semantic Kernel\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "先比较下影响力。\n",
            "\n",
            "<img src=\"star-history.png\" width=\"700\"/>\n",
            "\n",
            "数据来源：https://star-history.com/#langchain-ai/langchain&microsoft/semantic-kernel&hwchase17/langchainjs&Date\n",
            "\n",
            "LangChain 完胜？我们接下来仔细看看。\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "# LangChain.js\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Python 版 LangChain 的姊妹项目，都是由 Harrison Chase 主理。\n",
            "\n",
            "项目地址：https://github.com/langchain-ai/langchainjs\n",
            "\n",
            "文档地址：https://js.langchain.com/docs/\n",
            "\n",
            "特色：\n",
            "\n",
            "1. 可以和 Python 版 LangChain 无缝对接\n",
            "2. 抽象设计完全相同，概念一一对应\n",
            "3. 所有对象序列化后都能跨语言使用\n",
            "4. 但 API 差别挺大，不过在努力对齐\n",
            "\n",
            "支持环境：\n",
            "\n",
            "1. Node.js (ESM and CommonJS) - 18.x, 19.x, 20.x\n",
            "2. Cloudflare Workers\n",
            "3. Vercel / Next.js (Browser, Serverless and Edge functions)\n",
            "4. Supabase Edge Functions\n",
            "5. Browser\n",
            "6. Deno\n",
            "\n",
            "安装：\n",
            "\n",
            "```bash\n",
            "npm install langchain\n",
            "```\n",
            "\n",
            "当前重点：\n",
            "\n",
            "1. 追上 Python 版的能力（甚至为此做了一个基于 gpt-3.5-turbo 的[代码翻译器](https://langchain-translator.vercel.app/)）\n",
            "2. 保持兼容尽可能多的环境\n",
            "3. 对质量关注不多，随时间自然能解决\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## 两个防坑指南\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### 版本升级坑\n",
            "\n",
            "如果想 `npm update` 能更新 LangChain.js 到最新版，需要修改 `package.json`：\n",
            "\n",
            "```diff\n",
            "- \"langchain\": \"^0.0.155\",\n",
            "+ \"langchain\": \"~0.0.155\",\n",
            "```\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### 文档坑\n",
            "\n",
            "文档质量在持续提升，但稍微用深一些，还得读源码才行。\n",
            "\n",
            "比如最核心的一个函数，向 OpenAI 发出请求：https://js.langchain.com/docs/api/chat_models_openai/classes/ChatOpenAI#call\n",
            "\n",
            "![call](call.png)\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## 例子：chatall.ts\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "[chatall.ts](lcjs-samples/chatall.ts) 使用 LangChain.js 的 PromptTemplate 和 ChatOpenAI、ChatBaiduWenxin，测试批量 prompt 在不同大模型下的效果。\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## LangChain 的大杀器：LangSmith\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "🦜🔗 → 🦜🛠️\n",
            "\n",
            "- 非开源的商业 SaaS 项目：https://www.langchain.com/langsmith\n",
            "- 在线调试、测试和监视 prompt，和 LLM 应用\n",
            "- 因为太好用，甚至成为不想离开 LangChain 的理由（虽然它并没有和 LangChain 紧耦合）\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### 日志 LLM 应用\n",
            "\n",
            "只需要在 `.env` 中配置：\n",
            "\n",
            "```bash\n",
            "LANGCHAIN_TRACING_V2=true\n",
            "LANGCHAIN_ENDPOINT=https://api.smith.langchain.com\n",
            "LANGCHAIN_API_KEY=<your-api-key>  # LangSmith 中的 API Key\n",
            "LANGCHAIN_PROJECT=<your-project>  # 在 LangSmith 中创建的项目名。默认会使用 \"default\"\n",
            "```\n",
            "\n",
            "然后运行基于 LangChain 的应用，就能：\n",
            "\n",
            "- 在 LangSmith 中看到 LLM、Chain 等的调用日志\n",
            "- 就日志内容直接调试 prompt，创建数据集\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### 数据集\n",
            "\n",
            "- 数据集可以直接被代码引用，当做 prompt 中的例子\n",
            "- 可以批量跑数据集来测试模型效果\n",
            "- 内置若干[好用的评估能力](https://docs.smith.langchain.com/evaluation/evaluator-implementations)，也可以自定义\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Hub\n",
            "\n",
            "https://smith.langchain.com/hub\n",
            "\n",
            "- 类似 GitHub，可以和其它人共享 prompt\n",
            "- Hub 中的 prompt 可以直接在代码中引用\n",
            "\n",
            "```python\n",
            "from langchain import hub\n",
            "obj = hub.pull(\"homanp/superagent\")\n",
            "```\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### 启示\n",
            "\n",
            "<div class=\"alert alert-warning\">\n",
            "<b>未来产品经理和研发的分工：</b>\n",
            "<li>产品经理定义 prompt、chain、agent（简称 PCA），研发开发调试环境和生产环境</li>\n",
            "<li>PCA 的定义数据保存在独立 repo，独立进行版本管理，和代码解耦</li>\n",
            "<li>无需传统上线发布行为，就能改变产品的行为。这是另一种「热更新」</li>\n",
            "<li>以上工作就算都是一个人做，也值得解耦</li>\n",
            "</div>\n",
            "\n",
            "<div class=\"alert alert-success\">\n",
            "<b>划重点：</b>LangChain 做为 LLM 应用的浪尖项目，尽管它有很多缺点，但它所做的每件事，一定有真实需求在背后。就算不用 LangChain，也要学习它的思路，了解它的变化，掌握前沿\n",
            "</div>\n",
            "\n",
            "强烈建议订阅 [LangChain 的 blog](https://blog.langchain.dev/)。\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "# Semantic Kernel\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "先比较下 Semantic Kernel 和 LangChain。\n",
            "\n",
            "|          | Semantic Kernel              | LangChain          |\n",
            "| -------- | ---------------------------- | ------------------ |\n",
            "| 出品公司 | 微软                         | LangChain AI       |\n",
            "| 支持语言 | Python、C#、Java、TypeScript | Python、TypeScript |\n",
            "| 开源协议 | MIT                          | MIT                |\n",
            "| 被应用在 | Microsoft 365 Copilot、Bing  | 1.5w+ 开源项目     |\n",
            "\n",
            "当下，LangChain 更强。但 Semantic Kernel 可能更有未来，因为：\n",
            "\n",
            "1. 不要怀疑微软要做 AI 霸主的决心\n",
            "2. 不要轻视微软的架构和工程能力\n",
            "3. 以及，钞能力\n",
            "\n",
            "但微软的非中立性，可能带来问题。\n",
            "\n",
            "<img src=\"aiplugins.png\" width=\"500\"/>\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## SK 的开发进展\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Semantic Kernel 现在还是未正式发版状态。1.0.0 版预计今年底发布。\n",
            "\n",
            "1. C# 版最成熟，已开始 preview：https://github.com/microsoft/semantic-kernel\n",
            "2. Python 版还在 dev 状态，但可用：https://github.com/microsoft/semantic-kernel\n",
            "3. Java 版 alpha 阶段：https://github.com/microsoft/semantic-kernel/tree/experimental-java\n",
            "4. TypeScript 版……，可能已经放弃了：https://github.com/microsoft/semantic-kernel/tree/experimental-typescript\n",
            "5. 文档写得特别好，但追不上代码更新速度：\n",
            "   - 更多讲解：https://learn.microsoft.com/en-us/semantic-kernel/overview/\n",
            "   - 更偏实操：https://github.com/microsoft/semantic-kernel/blob/main/samples/notebooks/python/00-getting-started.ipynb\n",
            "\n",
            "这里可以了解最新进展：https://learn.microsoft.com/en-us/semantic-kernel/get-started/supported-languages\n",
            "\n",
            "不同语言之间的概念都是相通的。本课程以 Python 版为例。\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## SK 的生态位\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "与 LangChain 完全重叠。微软将此技术栈命名为 Copilot Stack。\n",
            "\n",
            "<img src=\"copilot-stack.png\" alt=\"SK 的生态位\" width=\"300\"/>\n",
            "\n",
            "解释：\n",
            "\n",
            "- Plugin extensibility: 插件扩展\n",
            "- Copilots: AI 助手（副驾驶），例如 GitHub Copilot、Office 365 Copilot、Windows Copilot\n",
            "- AI orchestration: AI 编排，SK 就在这里\n",
            "- Foundation models: 基础大模型，例如 GPT-4\n",
            "- AI infrastructure: AI 基础设施，例如 PyTorch、GPU\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## SK 基础架构\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "![SK 架构](mind-and-body-of-semantic-kernel.png)\n",
            "\n",
            "解释：\n",
            "\n",
            "- Models and Memory: 和 LangChain 的概念相同，类比为大脑\n",
            "- Connectors: 用来连接各种外部服务，类似驱动程序\n",
            "- Plugins: 用来连接内部技能\n",
            "- Triggers and actions: 外部系统的触发器和动作，类比为四肢\n",
            "\n",
            "Semantic Kernel 用 **Kernel** 命名，是因为它确实像个操作系统 kernel，做核心资源调配，各种资源都可以挂在它上。\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "jp-MarkdownHeadingCollapsed": true
         },
         "source": [
            "## SK vs. LangChain\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### 概念对照\n",
            "\n",
            "| LangChain        | Semantic Kernel  |\n",
            "| ---------------- | ---------------- |\n",
            "| Model            | Connector        |\n",
            "| Tools            | Connector        |\n",
            "| Vectorstore      | Connector        |\n",
            "| Memory           | Memory           |\n",
            "| Prompt Templates | Plugins          |\n",
            "| Chain            | Pipeline / Chain |\n",
            "| Agent            | Planner          |\n",
            "| TextSplitter     | text.\\*          |\n",
            "| OutputParser     | 无               |\n",
            "\n",
            "### 功能对照\n",
            "\n",
            "|               | LangChain | Semantic Kernel |\n",
            "| ------------- | --------: | --------------: |\n",
            "| 大模型        |       70+ |              5+ |\n",
            "| 向量数据库    |       50+ |              11 |\n",
            "| Agent/Planner |       10+ |               4 |\n",
            "\n",
            "SK 对集成第三方能力的态度：\n",
            "\n",
            "- 不希望放在自己的代码库中\n",
            "- 像操作系统一样，它只提供最基础的能力，其它的都是外部维护，按需安装\n",
            "- 参考：https://github.com/microsoft/semantic-kernel/blob/main/CONTRIBUTING.md#adding-plugins-and-memory-connectors\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "jp-MarkdownHeadingCollapsed": true
         },
         "source": [
            "## 环境搭建\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "1. 安装 Python 3.x：https://www.python.org/downloads/\n",
            "2. 安装 SK 包：`pip install semantic-kernel`\n",
            "3. 在项目目录创建 .env 文件，添加以下内容：\n",
            "\n",
            "```bash\n",
            "# .env\n",
            "OPENAI_API_KEY=\"\"\n",
            "OPENAI_API_BASE=\"\"\n",
            "AZURE_OPENAI_DEPLOYMENT_NAME=\"\"\n",
            "AZURE_OPENAI_ENDPOINT=\"\"\n",
            "AZURE_OPENAI_API_KEY=\"\"\n",
            "```\n",
            "\n",
            "OpenAI 和 Azure，配置好一个就行。\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "jp-MarkdownHeadingCollapsed": true
         },
         "source": [
            "## Hello, World!\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "这是一个简单示例。\n",
            "\n",
            "第一段代码是初始化。后面所有代码都要在执行过这段代码后，才能执行。\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 5,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "<semantic_kernel.kernel.Kernel at 0x1065941d0>"
                  ]
               },
               "execution_count": 5,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "import semantic_kernel as sk\n",
            "from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion\n",
            "import os\n",
            "\n",
            "# 加载 .env 到环境变量\n",
            "from dotenv import load_dotenv, find_dotenv\n",
            "_ = load_dotenv(find_dotenv())\n",
            "\n",
            "# 创建 semantic kernel\n",
            "kernel = sk.Kernel()\n",
            "\n",
            "# 配置 OpenAI 服务\n",
            "api_key = os.getenv('OPENAI_API_KEY')\n",
            "endpoint = os.getenv('OPENAI_API_BASE')\n",
            "model = OpenAIChatCompletion(\n",
            "    \"gpt-3.5-turbo\", api_key, endpoint=endpoint)\n",
            "\n",
            "# 把 LLM 服务加入 kernel\n",
            "# 可以加多个。第一个加入的会被默认使用，非默认的要被指定使用\n",
            "kernel.add_text_completion_service(\"my-gpt3\", model)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "执行讲笑话的 prompt。\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 6,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "好的，这是一个关于Hello world的笑话：\n",
                  "\n",
                  "程序员A对程序员B说：“我刚刚写了一个非常简单的Hello world程序。”\n",
                  "程序员B问：“真的吗？那你能不能把它运行起来？”\n",
                  "程序员A回答：“当然可以！”\n",
                  "程序员B疑惑地问：“那你为什么不运行它呢？”\n",
                  "程序员A笑着说：“因为我还没写完它的文档。”\n"
               ]
            }
         ],
         "source": [
            "# 定义 semantic function\n",
            "tell_joke_about = kernel.create_semantic_function(\"给我讲个关于{{$input}}的笑话吧\")\n",
            "\n",
            "# 看结果\n",
            "print(tell_joke_about(\"Hello world\"))"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "<div class=\"alert alert-success\">\n",
            "<b>划重点：</b>\n",
            "用我们熟悉的操作系统来类比，可以更好地理解 SK。\n",
            "<ol>\n",
            "<li>启动操作系统：<code>kernel = sk.Kernel()</code></li>\n",
            "<li>安装驱动程序：<code>kernel.add_xxx_service()</code></li>\n",
            "<li>安装应用程序：<code>func = kernel.create_semantic_function()</code></li>\n",
            "<li>运行应用程序：<code>func()</code></li>\n",
            "</ol>\n",
            "</div>\n",
            "\n",
            "基于 SK 开发的主要工作是写「应用程序」，也就是 Plugins\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "jp-MarkdownHeadingCollapsed": true
         },
         "source": [
            "## Plugins\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "简单说，plugin 就是一组函数的集合。它可以包含两种函数：\n",
            "\n",
            "- Semantic Functions - 语义函数，本质是 Prompt Engineering\n",
            "- Native Functions - 原生函数，类似 OpenAI 的 Function Calling\n",
            "\n",
            "值得一提的是，SK 的 plugin 会和 ChatGPT、Bing、Microsoft 365 通用。「很快」你用 SK 写的 plugin 就可以在这些平台上无缝使用了。这些平台上的 plugin 也可以通过 SK 被你调用。\n",
            "\n",
            "<div class=\"alert alert-warning\">\n",
            "<b>注意：</b>Plugins 最初命名为 Skills，后来改为 Plugins。但是无论文档还是代码，都还有大量的「Skill」遗留，预计到 1.0.0 发布才能清理干净。见到后，就知道两者是一回事就好\n",
            "</div>\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "jp-MarkdownHeadingCollapsed": true
         },
         "source": [
            "### Semantic Functions\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Semantic Functions 是纯用数据（prompt + 描述）定义的，不需要编写任何代码。所以它与编程语言无关，可以被任何编程语言调用。\n",
            "\n",
            "一个典型的 semantic function 包含两个文件：\n",
            "\n",
            "- skprompt.txt: 存放 prompt，可以包含参数，还可以调用其它函数\n",
            "- config.json: 存放描述，包括函数功能，参数的数据类型，以及调用大模型时的参数\n",
            "\n",
            "举例：把 LangChain 「生成 Linux 命令」的例子用 SK 实现。\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "jp-MarkdownHeadingCollapsed": true
         },
         "source": [
            "#### skprompt.txt\n"
         ]
      },
      {
         "cell_type": "raw",
         "metadata": {},
         "source": [
            "将用户的指令转换成 Linux 命令\n",
            "\n",
            "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
            "\n",
            "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}}\n",
            "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
            "\n",
            "Here is the output schema:\n",
            "```\n",
            "{\"properties\": {\"command\": {\"title\": \"Command\", \"description\": \"linux shell命令名\", \"type\": \"string\"}, \"arguments\": {\"title\": \"Arguments\", \"description\": \"命令的参数 (name:value)\", \"type\": \"object\", \"additionalProperties\": {\"type\": \"string\"}}}, \"required\": [\"command\", \"arguments\"]}\n",
            "```\n",
            "\n",
            "{{$input}}"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "jp-MarkdownHeadingCollapsed": true
         },
         "source": [
            "#### config.json\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "{\n",
            "    \"schema\": 1,\n",
            "    \"type\": \"completion\",\n",
            "    \"description\": \"将用户的指令转换成 Linux 命令\",\n",
            "    \"completion\": {\n",
            "        \"max_tokens\": 256,\n",
            "        \"temperature\": 0,\n",
            "        \"top_p\": 0,\n",
            "        \"presence_penalty\": 0,\n",
            "        \"frequency_penalty\": 0\n",
            "    },\n",
            "    \"input\": {\n",
            "        \"parameters\": [\n",
            "            {\n",
            "                \"name\": \"input\",\n",
            "                \"description\": \"用户的指令\",\n",
            "                \"defaultValue\": \"\"\n",
            "            }\n",
            "        ]\n",
            "    }\n",
            "}"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "上面两个文件都在 [sk_samples/SamplePlugin/GenerateCommand](sk_samples/SamplePlugin/GenerateCommand/) 目录下。\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "jp-MarkdownHeadingCollapsed": true
         },
         "source": [
            "#### 调用 Semantic Functions\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 8,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "{\n",
                  "  \"command\": \"date\",\n",
                  "  \"arguments\": {\n",
                  "    \"-s\": \"2023-04-01\"\n",
                  "  }\n",
                  "}\n"
               ]
            }
         ],
         "source": [
            "# 加载 semantic function。注意目录结构\n",
            "functions = kernel.import_semantic_skill_from_directory(\n",
            "    \"./sk_samples/\", \"SamplePlugin\")\n",
            "cli = functions[\"GenerateCommand\"]\n",
            "\n",
            "# 看结果\n",
            "print(cli(\"将系统日期设为2023-04-01\"))"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "官方提供了大量的 Semantic Functions 可以参考：https://github.com/microsoft/semantic-kernel/tree/main/samples/skills\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "jp-MarkdownHeadingCollapsed": true
         },
         "source": [
            "### Semantic Kernel Tools\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "这是个 VS Code 的插件，在 VS Code 里可以直接创建和调试 Semantic Function。\n",
            "\n",
            "安装地址：https://marketplace.visualstudio.com/items?itemName=ms-semantic-kernel.semantic-kernel\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "jp-MarkdownHeadingCollapsed": true
         },
         "source": [
            "### Native Functions\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "用编程语言写的函数，如果用 SK 的 Native Function 方式定义，就能纳入到 SK 的编排体系，可以被 Planner、其它 plugin 调用。\n",
            "\n",
            "下面，写一个过滤有害 Linux 命令的函数，和 GenerateCommand 组合使用。\n",
            "\n",
            "这个函数名是 `harmful_command`。如果输入的命令是有害的，就返回 `true`，否则返回 `false`。\n",
            "\n",
            "它也要放到目录结构中，在 [sk_samples/SamplePlugin/SamplePlugin.py](sk_samples/SamplePlugin/SamplePlugin.py) 里加入。\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 9,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "{\n",
                  "  \"command\": \"rm\",\n",
                  "  \"arguments\": {\n",
                  "    \"-rf\": \"/\"\n",
                  "  }\n",
                  "}\n",
                  "true\n"
               ]
            }
         ],
         "source": [
            "# 因为是代码，不是数据，所以必须 import\n",
            "from sk_samples.SamplePlugin.SamplePlugin import SamplePlugin\n",
            "\n",
            "# 加载 semantic function\n",
            "functions = kernel.import_semantic_skill_from_directory(\n",
            "    \"./sk_samples/\", \"SamplePlugin\")\n",
            "cli = functions[\"GenerateCommand\"]\n",
            "\n",
            "# 加载 native function\n",
            "functions = kernel.import_skill(SamplePlugin(), \"SamplePlugin\")\n",
            "harmful_command = functions[\"harmful_command\"]\n",
            "\n",
            "# 看结果\n",
            "command = cli(\"删除根目录下所有文件\")\n",
            "print(command)  # 这个 command 其实是 SKContext 类型\n",
            "print(harmful_command(context=command))  # 所以要传参给 context"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "jp-MarkdownHeadingCollapsed": true
         },
         "source": [
            "### 用 SKContext 实现多参数 Functions\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "如果 Function 都只有一个参数，那么只要把参数定义为 `{{$input}}`，就可以按前面的例子来使用，比较直观。`{{$input}}`会默认被赋值。\n",
            "\n",
            "多参数时，就不能用默认机制了，需要定义 `SKContext` 类型的变量。\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 10,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "66560.0\n"
               ]
            }
         ],
         "source": [
            "# 因为是代码，不是数据，所以必须 import\n",
            "from sk_samples.SamplePlugin.SamplePlugin import SamplePlugin\n",
            "\n",
            "# 加载 native function\n",
            "functions = kernel.import_skill(SamplePlugin(), \"SamplePlugin\")\n",
            "add = functions[\"add\"]\n",
            "\n",
            "# 看结果\n",
            "context = kernel.create_new_context()\n",
            "context[\"number1\"] = 1024\n",
            "context[\"number2\"] = 65536\n",
            "total = add(context=context)\n",
            "print(total)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "jp-MarkdownHeadingCollapsed": true
         },
         "source": [
            "### 内置 Plugins\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "SK 内置了若干好用的 plugin，但因为历史原因，它们叫 skill……\n",
            "\n",
            "加载方法：\n",
            "\n",
            "```python\n",
            "from semantic_kernel.core_skills import SkillName\n",
            "```\n",
            "\n",
            "它们是：\n",
            "\n",
            "- [`ConversationSummarySkill`](https://github.com/microsoft/semantic-kernel/blob/main/python/semantic_kernel/core_skills/conversation_summary_skill.py) - 生成对话的摘要\n",
            "- [`FileIOSkill`](https://github.com/microsoft/semantic-kernel/blob/main/python/semantic_kernel/core_skills/file_io_skill.py) - 读写文件\n",
            "- [`HttpSkill`](https://github.com/microsoft/semantic-kernel/blob/main/python/semantic_kernel/core_skills/http_skill.py) - 发出 HTTP 请求，支持 GET、POST、PUT 和 DELETE\n",
            "- [`MathSkill`](https://github.com/microsoft/semantic-kernel/blob/main/python/semantic_kernel/core_skills/math_skill.py) - 加法和减法计算\n",
            "- [`TextMemorySkill`](https://github.com/microsoft/semantic-kernel/blob/main/python/semantic_kernel/core_skills/text_memory_skill.py) - 保存文本到 memory 中，可以对其做向量检索\n",
            "- [`TextSkill`](https://github.com/microsoft/semantic-kernel/blob/main/python/semantic_kernel/core_skills/text_skill.py) - 把文本全部转为大写或小写，去掉头尾的空格（trim）\n",
            "- [`TimeSkill`](https://github.com/microsoft/semantic-kernel/blob/main/python/semantic_kernel/core_skills/time_skill.py) - 获取当前时间及用多种格式获取时间参数\n",
            "- [`WaitSkill`](https://github.com/microsoft/semantic-kernel/blob/main/python/semantic_kernel/core_skills/wait_skill.py) - 等待指定的时间\n",
            "- [`WebSearchEngineSkill`](https://github.com/microsoft/semantic-kernel/blob/main/python/semantic_kernel/core_skills/web_search_engine_skill.py) - 在互联网上搜索给定的文本\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "jp-MarkdownHeadingCollapsed": true
         },
         "source": [
            "## Memory\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "SK 的 memory 使用非常简单：\n",
            "\n",
            "1. 用 `kernel.add_text_embedding_generation_service()` 添加一个文本向量生成服务\n",
            "2. 用 `kernel.register_memory_store()` 注册一个 memory store，可以是内存、文件、向量数据库等\n",
            "3. 用 `kernel.memory.save_information_async()` 保存信息到 memory store\n",
            "4. 用 `kernel.memory.search_async()` 搜索信息\n",
            "\n",
            "使用 ChatALL 的 README.md 做数据，使用内存作为 memory store，我们演示下基于文档对话。\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "jp-MarkdownHeadingCollapsed": true
         },
         "source": [
            "### 初始化 Embedding\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 11,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "<semantic_kernel.kernel.Kernel at 0x1154f5650>"
                  ]
               },
               "execution_count": 11,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "import semantic_kernel as sk\n",
            "from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion, OpenAITextEmbedding\n",
            "import os\n",
            "\n",
            "# 加载 .env 到环境变量\n",
            "from dotenv import load_dotenv, find_dotenv\n",
            "_ = load_dotenv(find_dotenv())\n",
            "\n",
            "# 创建 semantic kernel\n",
            "kernel = sk.Kernel()\n",
            "\n",
            "# 配置 OpenAI 服务\n",
            "api_key = os.getenv('OPENAI_API_KEY')\n",
            "endpoint = os.getenv('OPENAI_API_BASE')\n",
            "model = OpenAIChatCompletion(\n",
            "    \"gpt-3.5-turbo\", api_key, endpoint=endpoint)\n",
            "\n",
            "# 把 LLM 服务加入 kernel\n",
            "# 可以加多个。第一个加入的会被默认使用，非默认的要被指定使用\n",
            "kernel.add_text_completion_service(\"my-gpt3\", model)\n",
            "\n",
            "# 添加 embedding 服务\n",
            "kernel.add_text_embedding_generation_service(\n",
            "    \"ada\", OpenAITextEmbedding(\"text-embedding-ada-002\", api_key, endpoint=endpoint))"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "jp-MarkdownHeadingCollapsed": true
         },
         "source": [
            "### 文本向量化\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 12,
         "metadata": {},
         "outputs": [],
         "source": [
            "from semantic_kernel.text import split_markdown_lines\n",
            "\n",
            "# 使用内存做 memory store\n",
            "kernel.register_memory_store(memory_store=sk.memory.VolatileMemoryStore())\n",
            "\n",
            "# 读取文件内容\n",
            "with open('ChatALL.md', 'r') as f:\n",
            "    # with open('sk_samples/SamplePlugin/SamplePlugin.py', 'r') as f:\n",
            "    content = f.read()\n",
            "\n",
            "# 将文件内容分片，单片最大 100 token（注意：SK 的 text split 功能目前对中文支持不如对英文支持得好）\n",
            "lines = split_markdown_lines(content, 100)\n",
            "\n",
            "# 将分片后的内容，存入内存\n",
            "for index, line in enumerate(lines):\n",
            "    await kernel.memory.save_information_async(\"chatall\", id=index, text=line)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "jp-MarkdownHeadingCollapsed": true
         },
         "source": [
            "### 向量搜索\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 13,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "拥有可以访问这些 AI 的帐号，或 API token。\n",
                  "2. 与 AI 网站有可靠的网络连接。\n",
                  "\n",
                  "## 下载 / 安装\n",
                  "\n",
                  "从 https://github.com/sunner/ChatALL/releases 下载\n",
                  "\n",
                  "### Windows 系统\n",
                  "\n",
                  "直接下载 \\*-win.exe 安装文件并运行之。\n",
                  "\n",
                  "### macOS 系统\n",
                  "\n",
                  "对于苹果硅芯片 Mac（M1，M2 CPU），请下载 \\*-mac-arm64.\n"
               ]
            }
         ],
         "source": [
            "result = await kernel.memory.search_async(\"chatall\", \"ChatALL怎么下载？\")\n",
            "print(result[0].text)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "jp-MarkdownHeadingCollapsed": true
         },
         "source": [
            "## Pipeline / Chain\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "SK 更想用 pipeline 来描述 LangChain 中 chain 的概念，大概因为 pipeline 这个词更操作系统吧。但 chain 这个名词影响力太大，所以 SK 时不时也会用它。\n",
            "\n",
            "但是，SK 没有在代码里定义什么是 pipeline，它并不是一个类，或者函数什么的。它是贯彻整个 kernel 的一个概念。\n",
            "\n",
            "当一个 kernel 添加了 LLM、memory、functions，我们写下的 functions 之间的组合调用，就是个 pipeline 了。\n",
            "\n",
            "如果需要多条 pipeline，就定义多个 kernel。\n",
            "\n",
            "<div class=\"alert alert-block alert-info\">\n",
            "<b>思考：</b>LangChain 定义了好几种 Chain；SK 只是用 kernel 把抽象功能组合起来，pipeline 的过程完全交给开发者自己定义。你觉得哪种设计更好？\n",
            "</div>\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "现在用 pipeline 思想把对话式搜索 ChatALL 的 README.md 功能做完整。\n",
            "\n",
            "在自定义的 Semantic Function 中，嵌套调用内置的 `TextMemorySkill`。\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 14,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "从 https://github.com/sunner/ChatALL/releases 下载安装文件。对于Windows系统，下载\\*-win.exe文件并运行；对于苹果硅芯片Mac系统，请下载\\*-mac-arm64文件。\n"
               ]
            }
         ],
         "source": [
            "# 导入内置的 `TextMemorySkill`。主要使用它的 `recall()`\n",
            "kernel.import_skill(sk.core_skills.TextMemorySkill())\n",
            "\n",
            "# 直接在代码里创建 semantic function。真实工程不建议这么做\n",
            "# 里面调用了 `recall()`\n",
            "sk_prompt = \"\"\"\n",
            "基于下面的背景信息回答问题。如果背景信息为空，或者和问题不相关，请回答\"我不知道\"。\n",
            "\n",
            "[背景信息开始]\n",
            "{{recall $input}}\n",
            "[背景信息结束]\n",
            "\n",
            "问题：{{$input}}\n",
            "回答：\n",
            "\"\"\"\n",
            "ask = kernel.create_semantic_function(sk_prompt)\n",
            "\n",
            "# 提问\n",
            "context = kernel.create_new_context()\n",
            "context[sk.core_skills.TextMemorySkill.COLLECTION_PARAM] = \"chatall\"\n",
            "context[sk.core_skills.TextMemorySkill.RELEVANCE_PARAM] = 0.8\n",
            "context[\"input\"] = \"ChatALL 怎么下载？\"\n",
            "result = ask(context=context)\n",
            "print(result)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "用更 pipeline 的方式实现同样的功能\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 15,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "从 https://github.com/sunner/ChatALL/releases 下载安装文件，并根据操作系统选择对应的文件进行下载。对于Windows系统，下载\\*-win.exe文件并运行；对于苹果硅芯片Mac系统，请下载\\*-mac-arm64文件。\n"
               ]
            }
         ],
         "source": [
            "# 导入内置的 `TextMemorySkill`。主要使用它的 `recall()`\n",
            "text_memory_functions = kernel.import_skill(sk.core_skills.TextMemorySkill())\n",
            "recall = text_memory_functions[\"recall\"]\n",
            "\n",
            "# 直接在代码里创建 semantic function。真实工程不建议这么做\n",
            "sk_prompt = \"\"\"\n",
            "基于下面的背景信息回答问题。如果背景信息为空，或者和问题不相关，请回答\"我不知道\"。\n",
            "\n",
            "[背景信息开始]\n",
            "{{$input}}\n",
            "[背景信息结束]\n",
            "\n",
            "问题：{{$user_input}}\n",
            "回答：\n",
            "\"\"\"\n",
            "ask = kernel.create_semantic_function(sk_prompt)\n",
            "\n",
            "# 准备 context\n",
            "context = kernel.create_new_context()\n",
            "context[sk.core_skills.TextMemorySkill.COLLECTION_PARAM] = \"chatall\"\n",
            "context[sk.core_skills.TextMemorySkill.RELEVANCE_PARAM] = 0.8\n",
            "context[\"input\"] = \"ChatALL 怎么下载？\"\n",
            "context[\"user_input\"] = \"ChatALL 怎么下载？\"\n",
            "\n",
            "# pipeline\n",
            "result = await kernel.run_async(recall, ask, input_context=context)\n",
            "print(result)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Planner\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "SK 的 planner 概念上对标 LangChain 的 agent，但做得比较简单，还比较初步。\n",
            "\n",
            "SK Python 提供了四种 planner：\n",
            "\n",
            "1. `SequentialPlanner`\n",
            "   - 制定包含一系列步骤的计划，这些步骤通过自定义生成的输入和输出变量相互连接\n",
            "   - 核心 prompt：https://github.com/microsoft/semantic-kernel/blob/main/python/semantic_kernel/planning/sequential_planner/Skills/SequentialPlanning/skprompt.txt\n",
            "   - 官方例程：https://github.com/microsoft/semantic-kernel/blob/main/python/samples/kernel-syntax-examples/sequential_planner.py\n",
            "2. `ActionPlanner`\n",
            "   - 类似 OpenAI Function Calling，从 kernel 中已注册的所有 plugin 中找到一个该执行的函数\n",
            "   - 核心 prompt：https://github.com/microsoft/semantic-kernel/blob/main/python/semantic_kernel/planning/action_planner/skprompt.txt\n",
            "   - 官方例程：https://github.com/microsoft/semantic-kernel/blob/main/python/samples/kernel-syntax-examples/action_planner.py\n",
            "3. `StepwisePlanner`\n",
            "   - 每执行完一步，都做一下复盘\n",
            "   - 已发布。只输出 action，不执行\n",
            "   - 核心 prompt：https://github.com/microsoft/semantic-kernel/blob/main/python/semantic_kernel/planning/stepwise_planner/Skills/StepwiseStep/skprompt.txt\n",
            "4. `BasicPlanner`\n",
            "   - **不建议使用**。把任务拆解，自动调用各个函数，完成任务。它只是个用于基础验证的功能，最终会被 `SequentialPlanner` 替代\n",
            "   - 核心 prompt：https://github.com/microsoft/semantic-kernel/blob/main/python/semantic_kernel/planning/basic_planner.py#L27-L123\n",
            "\n",
            "使用 planner 的步骤非常简单：\n",
            "\n",
            "1. 把 plugin 注册到 kernel\n",
            "2. 把 kernel 当参数实例化某个 planner\n",
            "3. 调用 planner 的 `create_plan_async()` 方法获得 plan\n",
            "4. 调用 plan 的 `invoke_async()` 方法执行 plan\n",
            "\n",
            "(注意，不同 planner 接口并不一致，不能简单平替)\n",
            "\n",
            "下面，把查周杰伦的生日是星期几，用 `SequentialPlanner` 再做一遍。\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 1,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Step: 0\n",
                  "Description: Performs a web search for a given query\n",
                  "Function: WebSearch.searchAsync\n",
                  "  Output:\n",
                  " ['关注. 展开全部. 阳历1979年1月18日星期四 农历 己未年 农历12月20日 姓名:周杰伦 英文名:Jay chou 出生：1979年1月18日 学历：淡江中学音乐科 生肖:马 血型：O型 星座：魔羯座 身高：175cm 体重：60kg 专长：写歌、作词、打球 专精乐器：钢琴、大提琴、吉他 ...']\n",
                  "Step: 1\n",
                  "Description: 输出 input 中出现的第一个日期是星期几\n",
                  "Function: DatePlugin.DayOfWeek\n",
                  "  Output:\n",
                  " 星期四\n",
                  "星期四\n"
               ]
            }
         ],
         "source": [
            "from semantic_kernel.core_skills import WebSearchEngineSkill\n",
            "from semantic_kernel.connectors.search_engine import BingConnector\n",
            "from semantic_kernel.planning import SequentialPlanner\n",
            "import semantic_kernel as sk\n",
            "from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion\n",
            "import os\n",
            "\n",
            "# 加载 .env 到环境变量\n",
            "from dotenv import load_dotenv, find_dotenv\n",
            "_ = load_dotenv(find_dotenv())\n",
            "\n",
            "# 创建 semantic kernel\n",
            "kernel = sk.Kernel()\n",
            "\n",
            "# 配置 OpenAI 服务\n",
            "api_key = os.getenv('OPENAI_API_KEY')\n",
            "endpoint = os.getenv('OPENAI_API_BASE')\n",
            "model = OpenAIChatCompletion(\n",
            "    \"gpt-3.5-turbo\", api_key, endpoint=endpoint)\n",
            "\n",
            "# 把 LLM 服务加入 kernel\n",
            "# 可以加多个。第一个加入的会被默认使用，非默认的要被指定使用\n",
            "kernel.add_text_completion_service(\"my-gpt4\", model)\n",
            "\n",
            "# 导入搜索 plugin\n",
            "connector = BingConnector(api_key=os.getenv(\"BING_API_KEY\"))\n",
            "kernel.import_skill(WebSearchEngineSkill(connector), \"WebSearch\")\n",
            "\n",
            "# 使用 DayOfWeek()\n",
            "# kernel.import_semantic_skill_from_directory(\"./sk_samples/\", \"SamplePlugin\")\n",
            "\n",
            "sk_prompt = \"\"\"\n",
            "以下内容里出现的第一个日期是星期几？只输出星期几\n",
            "\n",
            "{{$input}}\n",
            "\"\"\"\n",
            "kernel.create_semantic_function(\n",
            "    sk_prompt, \"DayOfWeek\", \"DatePlugin\", \"输出 input 中出现的第一个日期是星期几\")\n",
            "\n",
            "# 创建 planner\n",
            "planner = SequentialPlanner(kernel)\n",
            "\n",
            "# 开始\n",
            "ask = \"周杰伦的生日是星期几？\"\n",
            "plan = await planner.create_plan_async(goal=ask)\n",
            "\n",
            "result = await plan.invoke_async(logger=print)\n",
            "\n",
            "# 打印步骤用来调试\n",
            "for index, step in enumerate(plan._steps):\n",
            "    print(\"Step:\", index)\n",
            "    print(\"Description:\", step.description)\n",
            "    print(\"Function:\", step.skill_name + \".\" + step._function.name)\n",
            "    if len(step._outputs) > 0:\n",
            "        print(\"  Output:\\n\", str.replace(\n",
            "            result[step._outputs[0]], \"\\n\", \"\\n  \"))\n",
            "\n",
            "\n",
            "print(result)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## 用 Prompt Flow 调试和评估\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "[Prompt flow](https://github.com/microsoft/promptflow) 可以对标 LangSmith，但区别挺大。\n",
            "\n",
            "- 是个 VS Code 插件 + 命令行工具\n",
            "- 可以和 SK 配合，也可以独立使用\n",
            "- 可视化 flow 组合 prompt 和代码，调试参数，用数据集评估效果\n",
            "- 代码可直接部署到 Azure\n",
            "- [flows/chat/](flows/chat/) 演示了纯靠 prompt flow 拼接，实现和 LLM 对话，但每次的输出都用 LLM 做摘要，以节约阅读时间\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "# LangChain 和 Semantic Kernel 怎么选？\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "<div class=\"alert alert-success\">\n",
            "<b>划重点：</b>\n",
            "<ol>\n",
            "<li>两者都值得学</li>\n",
            "<li>C#、Java 只能用 SK，JavaScript 只能用 LangChain</li>\n",
            "<li>做原型，首选 LangChain。功能多，开发快</li>\n",
            "<li>做产品，还是 SK 长期更可依赖</li>\n",
            "</ol>\n",
            "</div>\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "多说两句：\n",
            "\n",
            "- LC 和 SK 的区别即是创业和大厂的区别，也是算法思维和工程思维的区别\n",
            "- 论文上的理论，仿真出的算法，落到工程项目，常常需要重写。这不是 Python 的问题\n",
            "- 算法科学家不懂工程，软件工程师不懂算法，这是 AI 剧烈发展带来的真空地带\n",
            "- 谁来填补？\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## 其它值得关注的框架\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### LlamaIndex\n",
            "\n",
            "[LlamaIndex](https://github.com/run-llama/llama_index) 是一个建造 LLM 应用的**数据框架**\n",
            "\n",
            "- GitHub 22k+ stars\n",
            "- 专门针对搜索、检索类 LLM 应用优化，性能不错\n",
            "- 接口简单直接，易于上手\n",
            "- 外部数据的对接极其方便：https://llamahub.ai/\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### MetaGPT\n",
            "\n",
            "[MetaGPT](https://github.com/geekan/MetaGPT) 国内公司开发的多 Agent 框架\n",
            "\n",
            "- GitHub 27k+ stars\n",
            "- 并不是 AI 编程工具，而是个开发框架\n",
            "- 多 Agent 的概念非常超前。虽然实用性还不行，但值得关注\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## 它们都可以组合使用\n",
            "\n",
            "各取其长，但对我们的要求更高，免不了要读源代码来分析它们，找到最佳的组合策略（过程中，可能会发现，有些部分自己做更好）。\n",
            "\n",
            "<div class=\"alert alert-success\">\n",
            "组合套路：\n",
            "<ol>\n",
            "<li>用 SK 搭框架，用它的 Connectors 和 Plugins 能力</li>\n",
            "<li>用 LangChain 的各种小工具做局部处理，比如 TextSplitter、OutputParser</li>\n",
            "<li>用 LlamaIndex 对接外部数据</li>\n",
            "<li>用 Prompt Flow 调试和评估</li>\n",
            "<li>用 LangSmith 监视 LLM 流量</li>\n",
            "<li>自建自己的 agent（特定场景的 agent 一定不是通用的）</li>\n",
            "</ol>\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "jp-MarkdownHeadingCollapsed": true
         },
         "source": [
            "# 参与开源软件开发，正当时\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "<div class=\"alert alert-warning\">\n",
            "<b>为什么要为开源软件贡献代码：</b>\n",
            "<li>这是一个于己、于他人都有好处的共享事业</li>\n",
            "<li>大模型相关的开源软件都在起步阶段，有很多低垂的果实</li>\n",
            "<li>LangChain 和 SK 对国产大模型支持有限，这是好机会</li>\n",
            "<li>过程中能对机理了解更深</li>\n",
            "<li>在简历中是个亮色</li>\n",
            "</div>\n",
            "\n",
            "有些所谓技术高手号称给重要的开源软件贡献过代码，但深扒一下可以发现，只是改了改文档而已，写测试用例的都算深入了。\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "jp-MarkdownHeadingCollapsed": true
         },
         "source": [
            "## 怎么贡献\n",
            "\n",
            "### 准备\n",
            "\n",
            "1. 只能用英语\n",
            "2. 熟读贡献指导（[LangChain Python 版](https://github.com/hwchase17/langchain/blob/master/.github/CONTRIBUTING.md)、[LangChain JS 版](https://github.com/hwchase17/langchainjs/blob/main/CONTRIBUTING.md)、[Semantic Kernel](https://github.com/microsoft/semantic-kernel/blob/main/CONTRIBUTING.md)），了解详细的流程、要求、注意事项等\n",
            "\n",
            "如果以上两步不能坚持，此处可以放弃，也必须放弃了……\n",
            "\n",
            "### 选题\n",
            "\n",
            "1. 完善文档、做语言翻译是不错的起手式，可以体验下全流程。符合流程很重要，不然可能反倒是给人家添麻烦\n",
            "2. 从 issues 里面找一个你感兴趣的，或者自己提一个，最好是能解决实际问题的，询问项目维护人自己是否可以接这个 issue。得到同意，就可以动手了\n",
            "3. 国产大模型风起云涌，LangChain 和 SK 也需要支持更多的大模型，可以从这方面入手\n",
            "\n",
            "### 动手\n",
            "\n",
            "过程中肯定会遇到很多问题。技术上的，规范上的，语言上的等等。攻克这些问题，是很大的锻炼。\n",
            "\n",
            "代码被接受的那一刻，成就感是非常强的。\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "# 总结\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "1. LangChain.js 和 LangChain 保持了概念一致，功能丰富，很适合前端同学使用\n",
            "2. Semantic Kernel 架构设计更好，未来发展潜力更大，值得跟踪、尝试\n",
            "3. 趁它们都还不完善，正是参与开源软件建设的好时机\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "jp-MarkdownHeadingCollapsed": true
         },
         "source": [
            "# 作业\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "为自己选一个主攻方向吧，LangChain、LangChain.js 或 Semantic Kernel。然后用它来完成所有作业、项目。\n"
         ]
      }
   ],
   "metadata": {
      "kernelspec": {
         "display_name": "Python 3 (ipykernel)",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.11.6"
      }
   },
   "nbformat": 4,
   "nbformat_minor": 4
}
