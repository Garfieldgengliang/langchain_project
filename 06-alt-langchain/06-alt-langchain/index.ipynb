{
   "cells": [
      {
         "cell_type": "markdown",
         "metadata": {
            "jp-MarkdownHeadingCollapsed": true
         },
         "source": [
            "# ğŸ’¡ è¿™èŠ‚è¯¾ä¼šå¸¦ç»™ä½ \n",
            "\n",
            "1. LangChain.js å’Œ LangSmith\n",
            "2. Semantic Kernel çš„ç‰¹ç‚¹å’ŒåŸºæœ¬ç”¨æ³•\n",
            "3. å¦‚ä½•é€‰æ‹©é€‚åˆè‡ªå·±çš„ LLM å¼€å‘å¹³å°\n",
            "4. å¦‚ä½•ç»™å¼€æºè½¯ä»¶è´¡çŒ®ä»£ç \n",
            "\n",
            "å¼€å§‹ä¸Šè¯¾ï¼\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "# å¤§è¯­è¨€æ¨¡å‹å¼€å‘æ¡†æ¶çš„ä»·å€¼æ˜¯ä»€ä¹ˆï¼Ÿ\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "æ‰€æœ‰æ¡†æ¶çš„æ ¸å¿ƒä»·å€¼ï¼Œéƒ½æ˜¯é™ä½å¼€å‘ã€ç»´æŠ¤æˆæœ¬ã€‚\n",
            "\n",
            "å¤§è¯­è¨€æ¨¡å‹å¼€å‘æ¡†æ¶çš„ä»·å€¼ï¼Œæ˜¯è®©å¼€å‘è€…å¯ä»¥æ›´æ–¹ä¾¿åœ°å¼€å‘åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„åº”ç”¨ã€‚ä¸»è¦æä¾›ä¸¤ç±»å¸®åŠ©ï¼š\n",
            "\n",
            "1. ç¬¬ä¸‰æ–¹èƒ½åŠ›æŠ½è±¡ã€‚æ¯”å¦‚ LLMã€å‘é‡æ•°æ®åº“ã€æœç´¢å¼•æ“ç­‰\n",
            "2. å¸¸ç”¨å·¥å…·ã€æ–¹æ¡ˆå°è£…\n",
            "\n",
            "<div class=\"alert alert-success\">\n",
            "<b>åˆ’é‡ç‚¹ï¼š</b>é€‰å¯¹äº†æ¡†æ¶ï¼Œäº‹æƒ…æˆåŠŸä¸€åŠã€‚\n",
            "</div>\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "# LangChain vs. Semantic Kernel\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "å…ˆæ¯”è¾ƒä¸‹å½±å“åŠ›ã€‚\n",
            "\n",
            "<img src=\"star-history.png\" width=\"700\"/>\n",
            "\n",
            "æ•°æ®æ¥æºï¼šhttps://star-history.com/#langchain-ai/langchain&microsoft/semantic-kernel&hwchase17/langchainjs&Date\n",
            "\n",
            "LangChain å®Œèƒœï¼Ÿæˆ‘ä»¬æ¥ä¸‹æ¥ä»”ç»†çœ‹çœ‹ã€‚\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "# LangChain.js\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Python ç‰ˆ LangChain çš„å§Šå¦¹é¡¹ç›®ï¼Œéƒ½æ˜¯ç”± Harrison Chase ä¸»ç†ã€‚\n",
            "\n",
            "é¡¹ç›®åœ°å€ï¼šhttps://github.com/langchain-ai/langchainjs\n",
            "\n",
            "æ–‡æ¡£åœ°å€ï¼šhttps://js.langchain.com/docs/\n",
            "\n",
            "ç‰¹è‰²ï¼š\n",
            "\n",
            "1. å¯ä»¥å’Œ Python ç‰ˆ LangChain æ— ç¼å¯¹æ¥\n",
            "2. æŠ½è±¡è®¾è®¡å®Œå…¨ç›¸åŒï¼Œæ¦‚å¿µä¸€ä¸€å¯¹åº”\n",
            "3. æ‰€æœ‰å¯¹è±¡åºåˆ—åŒ–åéƒ½èƒ½è·¨è¯­è¨€ä½¿ç”¨\n",
            "4. ä½† API å·®åˆ«æŒºå¤§ï¼Œä¸è¿‡åœ¨åŠªåŠ›å¯¹é½\n",
            "\n",
            "æ”¯æŒç¯å¢ƒï¼š\n",
            "\n",
            "1. Node.js (ESM and CommonJS) - 18.x, 19.x, 20.x\n",
            "2. Cloudflare Workers\n",
            "3. Vercel / Next.js (Browser, Serverless and Edge functions)\n",
            "4. Supabase Edge Functions\n",
            "5. Browser\n",
            "6. Deno\n",
            "\n",
            "å®‰è£…ï¼š\n",
            "\n",
            "```bash\n",
            "npm install langchain\n",
            "```\n",
            "\n",
            "å½“å‰é‡ç‚¹ï¼š\n",
            "\n",
            "1. è¿½ä¸Š Python ç‰ˆçš„èƒ½åŠ›ï¼ˆç”šè‡³ä¸ºæ­¤åšäº†ä¸€ä¸ªåŸºäº gpt-3.5-turbo çš„[ä»£ç ç¿»è¯‘å™¨](https://langchain-translator.vercel.app/)ï¼‰\n",
            "2. ä¿æŒå…¼å®¹å°½å¯èƒ½å¤šçš„ç¯å¢ƒ\n",
            "3. å¯¹è´¨é‡å…³æ³¨ä¸å¤šï¼Œéšæ—¶é—´è‡ªç„¶èƒ½è§£å†³\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## ä¸¤ä¸ªé˜²å‘æŒ‡å—\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### ç‰ˆæœ¬å‡çº§å‘\n",
            "\n",
            "å¦‚æœæƒ³ `npm update` èƒ½æ›´æ–° LangChain.js åˆ°æœ€æ–°ç‰ˆï¼Œéœ€è¦ä¿®æ”¹ `package.json`ï¼š\n",
            "\n",
            "```diff\n",
            "- \"langchain\": \"^0.0.155\",\n",
            "+ \"langchain\": \"~0.0.155\",\n",
            "```\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### æ–‡æ¡£å‘\n",
            "\n",
            "æ–‡æ¡£è´¨é‡åœ¨æŒç»­æå‡ï¼Œä½†ç¨å¾®ç”¨æ·±ä¸€äº›ï¼Œè¿˜å¾—è¯»æºç æ‰è¡Œã€‚\n",
            "\n",
            "æ¯”å¦‚æœ€æ ¸å¿ƒçš„ä¸€ä¸ªå‡½æ•°ï¼Œå‘ OpenAI å‘å‡ºè¯·æ±‚ï¼šhttps://js.langchain.com/docs/api/chat_models_openai/classes/ChatOpenAI#call\n",
            "\n",
            "![call](call.png)\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## ä¾‹å­ï¼šchatall.ts\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "[chatall.ts](lcjs-samples/chatall.ts) ä½¿ç”¨ LangChain.js çš„ PromptTemplate å’Œ ChatOpenAIã€ChatBaiduWenxinï¼Œæµ‹è¯•æ‰¹é‡ prompt åœ¨ä¸åŒå¤§æ¨¡å‹ä¸‹çš„æ•ˆæœã€‚\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## LangChain çš„å¤§æ€å™¨ï¼šLangSmith\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "ğŸ¦œğŸ”— â†’ ğŸ¦œğŸ› ï¸\n",
            "\n",
            "- éå¼€æºçš„å•†ä¸š SaaS é¡¹ç›®ï¼šhttps://www.langchain.com/langsmith\n",
            "- åœ¨çº¿è°ƒè¯•ã€æµ‹è¯•å’Œç›‘è§† promptï¼Œå’Œ LLM åº”ç”¨\n",
            "- å› ä¸ºå¤ªå¥½ç”¨ï¼Œç”šè‡³æˆä¸ºä¸æƒ³ç¦»å¼€ LangChain çš„ç†ç”±ï¼ˆè™½ç„¶å®ƒå¹¶æ²¡æœ‰å’Œ LangChain ç´§è€¦åˆï¼‰\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### æ—¥å¿— LLM åº”ç”¨\n",
            "\n",
            "åªéœ€è¦åœ¨ `.env` ä¸­é…ç½®ï¼š\n",
            "\n",
            "```bash\n",
            "LANGCHAIN_TRACING_V2=true\n",
            "LANGCHAIN_ENDPOINT=https://api.smith.langchain.com\n",
            "LANGCHAIN_API_KEY=<your-api-key>  # LangSmith ä¸­çš„ API Key\n",
            "LANGCHAIN_PROJECT=<your-project>  # åœ¨ LangSmith ä¸­åˆ›å»ºçš„é¡¹ç›®åã€‚é»˜è®¤ä¼šä½¿ç”¨ \"default\"\n",
            "```\n",
            "\n",
            "ç„¶åè¿è¡ŒåŸºäº LangChain çš„åº”ç”¨ï¼Œå°±èƒ½ï¼š\n",
            "\n",
            "- åœ¨ LangSmith ä¸­çœ‹åˆ° LLMã€Chain ç­‰çš„è°ƒç”¨æ—¥å¿—\n",
            "- å°±æ—¥å¿—å†…å®¹ç›´æ¥è°ƒè¯• promptï¼Œåˆ›å»ºæ•°æ®é›†\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### æ•°æ®é›†\n",
            "\n",
            "- æ•°æ®é›†å¯ä»¥ç›´æ¥è¢«ä»£ç å¼•ç”¨ï¼Œå½“åš prompt ä¸­çš„ä¾‹å­\n",
            "- å¯ä»¥æ‰¹é‡è·‘æ•°æ®é›†æ¥æµ‹è¯•æ¨¡å‹æ•ˆæœ\n",
            "- å†…ç½®è‹¥å¹²[å¥½ç”¨çš„è¯„ä¼°èƒ½åŠ›](https://docs.smith.langchain.com/evaluation/evaluator-implementations)ï¼Œä¹Ÿå¯ä»¥è‡ªå®šä¹‰\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Hub\n",
            "\n",
            "https://smith.langchain.com/hub\n",
            "\n",
            "- ç±»ä¼¼ GitHubï¼Œå¯ä»¥å’Œå…¶å®ƒäººå…±äº« prompt\n",
            "- Hub ä¸­çš„ prompt å¯ä»¥ç›´æ¥åœ¨ä»£ç ä¸­å¼•ç”¨\n",
            "\n",
            "```python\n",
            "from langchain import hub\n",
            "obj = hub.pull(\"homanp/superagent\")\n",
            "```\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### å¯ç¤º\n",
            "\n",
            "<div class=\"alert alert-warning\">\n",
            "<b>æœªæ¥äº§å“ç»ç†å’Œç ”å‘çš„åˆ†å·¥ï¼š</b>\n",
            "<li>äº§å“ç»ç†å®šä¹‰ promptã€chainã€agentï¼ˆç®€ç§° PCAï¼‰ï¼Œç ”å‘å¼€å‘è°ƒè¯•ç¯å¢ƒå’Œç”Ÿäº§ç¯å¢ƒ</li>\n",
            "<li>PCA çš„å®šä¹‰æ•°æ®ä¿å­˜åœ¨ç‹¬ç«‹ repoï¼Œç‹¬ç«‹è¿›è¡Œç‰ˆæœ¬ç®¡ç†ï¼Œå’Œä»£ç è§£è€¦</li>\n",
            "<li>æ— éœ€ä¼ ç»Ÿä¸Šçº¿å‘å¸ƒè¡Œä¸ºï¼Œå°±èƒ½æ”¹å˜äº§å“çš„è¡Œä¸ºã€‚è¿™æ˜¯å¦ä¸€ç§ã€Œçƒ­æ›´æ–°ã€</li>\n",
            "<li>ä»¥ä¸Šå·¥ä½œå°±ç®—éƒ½æ˜¯ä¸€ä¸ªäººåšï¼Œä¹Ÿå€¼å¾—è§£è€¦</li>\n",
            "</div>\n",
            "\n",
            "<div class=\"alert alert-success\">\n",
            "<b>åˆ’é‡ç‚¹ï¼š</b>LangChain åšä¸º LLM åº”ç”¨çš„æµªå°–é¡¹ç›®ï¼Œå°½ç®¡å®ƒæœ‰å¾ˆå¤šç¼ºç‚¹ï¼Œä½†å®ƒæ‰€åšçš„æ¯ä»¶äº‹ï¼Œä¸€å®šæœ‰çœŸå®éœ€æ±‚åœ¨èƒŒåã€‚å°±ç®—ä¸ç”¨ LangChainï¼Œä¹Ÿè¦å­¦ä¹ å®ƒçš„æ€è·¯ï¼Œäº†è§£å®ƒçš„å˜åŒ–ï¼ŒæŒæ¡å‰æ²¿\n",
            "</div>\n",
            "\n",
            "å¼ºçƒˆå»ºè®®è®¢é˜… [LangChain çš„ blog](https://blog.langchain.dev/)ã€‚\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "# Semantic Kernel\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "å…ˆæ¯”è¾ƒä¸‹ Semantic Kernel å’Œ LangChainã€‚\n",
            "\n",
            "|          | Semantic Kernel              | LangChain          |\n",
            "| -------- | ---------------------------- | ------------------ |\n",
            "| å‡ºå“å…¬å¸ | å¾®è½¯                         | LangChain AI       |\n",
            "| æ”¯æŒè¯­è¨€ | Pythonã€C#ã€Javaã€TypeScript | Pythonã€TypeScript |\n",
            "| å¼€æºåè®® | MIT                          | MIT                |\n",
            "| è¢«åº”ç”¨åœ¨ | Microsoft 365 Copilotã€Bing  | 1.5w+ å¼€æºé¡¹ç›®     |\n",
            "\n",
            "å½“ä¸‹ï¼ŒLangChain æ›´å¼ºã€‚ä½† Semantic Kernel å¯èƒ½æ›´æœ‰æœªæ¥ï¼Œå› ä¸ºï¼š\n",
            "\n",
            "1. ä¸è¦æ€€ç–‘å¾®è½¯è¦åš AI éœ¸ä¸»çš„å†³å¿ƒ\n",
            "2. ä¸è¦è½»è§†å¾®è½¯çš„æ¶æ„å’Œå·¥ç¨‹èƒ½åŠ›\n",
            "3. ä»¥åŠï¼Œé’èƒ½åŠ›\n",
            "\n",
            "ä½†å¾®è½¯çš„éä¸­ç«‹æ€§ï¼Œå¯èƒ½å¸¦æ¥é—®é¢˜ã€‚\n",
            "\n",
            "<img src=\"aiplugins.png\" width=\"500\"/>\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## SK çš„å¼€å‘è¿›å±•\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Semantic Kernel ç°åœ¨è¿˜æ˜¯æœªæ­£å¼å‘ç‰ˆçŠ¶æ€ã€‚1.0.0 ç‰ˆé¢„è®¡ä»Šå¹´åº•å‘å¸ƒã€‚\n",
            "\n",
            "1. C# ç‰ˆæœ€æˆç†Ÿï¼Œå·²å¼€å§‹ previewï¼šhttps://github.com/microsoft/semantic-kernel\n",
            "2. Python ç‰ˆè¿˜åœ¨ dev çŠ¶æ€ï¼Œä½†å¯ç”¨ï¼šhttps://github.com/microsoft/semantic-kernel\n",
            "3. Java ç‰ˆ alpha é˜¶æ®µï¼šhttps://github.com/microsoft/semantic-kernel/tree/experimental-java\n",
            "4. TypeScript ç‰ˆâ€¦â€¦ï¼Œå¯èƒ½å·²ç»æ”¾å¼ƒäº†ï¼šhttps://github.com/microsoft/semantic-kernel/tree/experimental-typescript\n",
            "5. æ–‡æ¡£å†™å¾—ç‰¹åˆ«å¥½ï¼Œä½†è¿½ä¸ä¸Šä»£ç æ›´æ–°é€Ÿåº¦ï¼š\n",
            "   - æ›´å¤šè®²è§£ï¼šhttps://learn.microsoft.com/en-us/semantic-kernel/overview/\n",
            "   - æ›´åå®æ“ï¼šhttps://github.com/microsoft/semantic-kernel/blob/main/samples/notebooks/python/00-getting-started.ipynb\n",
            "\n",
            "è¿™é‡Œå¯ä»¥äº†è§£æœ€æ–°è¿›å±•ï¼šhttps://learn.microsoft.com/en-us/semantic-kernel/get-started/supported-languages\n",
            "\n",
            "ä¸åŒè¯­è¨€ä¹‹é—´çš„æ¦‚å¿µéƒ½æ˜¯ç›¸é€šçš„ã€‚æœ¬è¯¾ç¨‹ä»¥ Python ç‰ˆä¸ºä¾‹ã€‚\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## SK çš„ç”Ÿæ€ä½\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "ä¸ LangChain å®Œå…¨é‡å ã€‚å¾®è½¯å°†æ­¤æŠ€æœ¯æ ˆå‘½åä¸º Copilot Stackã€‚\n",
            "\n",
            "<img src=\"copilot-stack.png\" alt=\"SK çš„ç”Ÿæ€ä½\" width=\"300\"/>\n",
            "\n",
            "è§£é‡Šï¼š\n",
            "\n",
            "- Plugin extensibility: æ’ä»¶æ‰©å±•\n",
            "- Copilots: AI åŠ©æ‰‹ï¼ˆå‰¯é©¾é©¶ï¼‰ï¼Œä¾‹å¦‚ GitHub Copilotã€Office 365 Copilotã€Windows Copilot\n",
            "- AI orchestration: AI ç¼–æ’ï¼ŒSK å°±åœ¨è¿™é‡Œ\n",
            "- Foundation models: åŸºç¡€å¤§æ¨¡å‹ï¼Œä¾‹å¦‚ GPT-4\n",
            "- AI infrastructure: AI åŸºç¡€è®¾æ–½ï¼Œä¾‹å¦‚ PyTorchã€GPU\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## SK åŸºç¡€æ¶æ„\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "![SK æ¶æ„](mind-and-body-of-semantic-kernel.png)\n",
            "\n",
            "è§£é‡Šï¼š\n",
            "\n",
            "- Models and Memory: å’Œ LangChain çš„æ¦‚å¿µç›¸åŒï¼Œç±»æ¯”ä¸ºå¤§è„‘\n",
            "- Connectors: ç”¨æ¥è¿æ¥å„ç§å¤–éƒ¨æœåŠ¡ï¼Œç±»ä¼¼é©±åŠ¨ç¨‹åº\n",
            "- Plugins: ç”¨æ¥è¿æ¥å†…éƒ¨æŠ€èƒ½\n",
            "- Triggers and actions: å¤–éƒ¨ç³»ç»Ÿçš„è§¦å‘å™¨å’ŒåŠ¨ä½œï¼Œç±»æ¯”ä¸ºå››è‚¢\n",
            "\n",
            "Semantic Kernel ç”¨ **Kernel** å‘½åï¼Œæ˜¯å› ä¸ºå®ƒç¡®å®åƒä¸ªæ“ä½œç³»ç»Ÿ kernelï¼Œåšæ ¸å¿ƒèµ„æºè°ƒé…ï¼Œå„ç§èµ„æºéƒ½å¯ä»¥æŒ‚åœ¨å®ƒä¸Šã€‚\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "jp-MarkdownHeadingCollapsed": true
         },
         "source": [
            "## SK vs. LangChain\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### æ¦‚å¿µå¯¹ç…§\n",
            "\n",
            "| LangChain        | Semantic Kernel  |\n",
            "| ---------------- | ---------------- |\n",
            "| Model            | Connector        |\n",
            "| Tools            | Connector        |\n",
            "| Vectorstore      | Connector        |\n",
            "| Memory           | Memory           |\n",
            "| Prompt Templates | Plugins          |\n",
            "| Chain            | Pipeline / Chain |\n",
            "| Agent            | Planner          |\n",
            "| TextSplitter     | text.\\*          |\n",
            "| OutputParser     | æ—                |\n",
            "\n",
            "### åŠŸèƒ½å¯¹ç…§\n",
            "\n",
            "|               | LangChain | Semantic Kernel |\n",
            "| ------------- | --------: | --------------: |\n",
            "| å¤§æ¨¡å‹        |       70+ |              5+ |\n",
            "| å‘é‡æ•°æ®åº“    |       50+ |              11 |\n",
            "| Agent/Planner |       10+ |               4 |\n",
            "\n",
            "SK å¯¹é›†æˆç¬¬ä¸‰æ–¹èƒ½åŠ›çš„æ€åº¦ï¼š\n",
            "\n",
            "- ä¸å¸Œæœ›æ”¾åœ¨è‡ªå·±çš„ä»£ç åº“ä¸­\n",
            "- åƒæ“ä½œç³»ç»Ÿä¸€æ ·ï¼Œå®ƒåªæä¾›æœ€åŸºç¡€çš„èƒ½åŠ›ï¼Œå…¶å®ƒçš„éƒ½æ˜¯å¤–éƒ¨ç»´æŠ¤ï¼ŒæŒ‰éœ€å®‰è£…\n",
            "- å‚è€ƒï¼šhttps://github.com/microsoft/semantic-kernel/blob/main/CONTRIBUTING.md#adding-plugins-and-memory-connectors\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "jp-MarkdownHeadingCollapsed": true
         },
         "source": [
            "## ç¯å¢ƒæ­å»º\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "1. å®‰è£… Python 3.xï¼šhttps://www.python.org/downloads/\n",
            "2. å®‰è£… SK åŒ…ï¼š`pip install semantic-kernel`\n",
            "3. åœ¨é¡¹ç›®ç›®å½•åˆ›å»º .env æ–‡ä»¶ï¼Œæ·»åŠ ä»¥ä¸‹å†…å®¹ï¼š\n",
            "\n",
            "```bash\n",
            "# .env\n",
            "OPENAI_API_KEY=\"\"\n",
            "OPENAI_API_BASE=\"\"\n",
            "AZURE_OPENAI_DEPLOYMENT_NAME=\"\"\n",
            "AZURE_OPENAI_ENDPOINT=\"\"\n",
            "AZURE_OPENAI_API_KEY=\"\"\n",
            "```\n",
            "\n",
            "OpenAI å’Œ Azureï¼Œé…ç½®å¥½ä¸€ä¸ªå°±è¡Œã€‚\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "jp-MarkdownHeadingCollapsed": true
         },
         "source": [
            "## Hello, World!\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "è¿™æ˜¯ä¸€ä¸ªç®€å•ç¤ºä¾‹ã€‚\n",
            "\n",
            "ç¬¬ä¸€æ®µä»£ç æ˜¯åˆå§‹åŒ–ã€‚åé¢æ‰€æœ‰ä»£ç éƒ½è¦åœ¨æ‰§è¡Œè¿‡è¿™æ®µä»£ç åï¼Œæ‰èƒ½æ‰§è¡Œã€‚\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 5,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "<semantic_kernel.kernel.Kernel at 0x1065941d0>"
                  ]
               },
               "execution_count": 5,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "import semantic_kernel as sk\n",
            "from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion\n",
            "import os\n",
            "\n",
            "# åŠ è½½ .env åˆ°ç¯å¢ƒå˜é‡\n",
            "from dotenv import load_dotenv, find_dotenv\n",
            "_ = load_dotenv(find_dotenv())\n",
            "\n",
            "# åˆ›å»º semantic kernel\n",
            "kernel = sk.Kernel()\n",
            "\n",
            "# é…ç½® OpenAI æœåŠ¡\n",
            "api_key = os.getenv('OPENAI_API_KEY')\n",
            "endpoint = os.getenv('OPENAI_API_BASE')\n",
            "model = OpenAIChatCompletion(\n",
            "    \"gpt-3.5-turbo\", api_key, endpoint=endpoint)\n",
            "\n",
            "# æŠŠ LLM æœåŠ¡åŠ å…¥ kernel\n",
            "# å¯ä»¥åŠ å¤šä¸ªã€‚ç¬¬ä¸€ä¸ªåŠ å…¥çš„ä¼šè¢«é»˜è®¤ä½¿ç”¨ï¼Œéé»˜è®¤çš„è¦è¢«æŒ‡å®šä½¿ç”¨\n",
            "kernel.add_text_completion_service(\"my-gpt3\", model)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "æ‰§è¡Œè®²ç¬‘è¯çš„ promptã€‚\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 6,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "å¥½çš„ï¼Œè¿™æ˜¯ä¸€ä¸ªå…³äºHello worldçš„ç¬‘è¯ï¼š\n",
                  "\n",
                  "ç¨‹åºå‘˜Aå¯¹ç¨‹åºå‘˜Bè¯´ï¼šâ€œæˆ‘åˆšåˆšå†™äº†ä¸€ä¸ªéå¸¸ç®€å•çš„Hello worldç¨‹åºã€‚â€\n",
                  "ç¨‹åºå‘˜Bé—®ï¼šâ€œçœŸçš„å—ï¼Ÿé‚£ä½ èƒ½ä¸èƒ½æŠŠå®ƒè¿è¡Œèµ·æ¥ï¼Ÿâ€\n",
                  "ç¨‹åºå‘˜Aå›ç­”ï¼šâ€œå½“ç„¶å¯ä»¥ï¼â€\n",
                  "ç¨‹åºå‘˜Bç–‘æƒ‘åœ°é—®ï¼šâ€œé‚£ä½ ä¸ºä»€ä¹ˆä¸è¿è¡Œå®ƒå‘¢ï¼Ÿâ€\n",
                  "ç¨‹åºå‘˜Aç¬‘ç€è¯´ï¼šâ€œå› ä¸ºæˆ‘è¿˜æ²¡å†™å®Œå®ƒçš„æ–‡æ¡£ã€‚â€\n"
               ]
            }
         ],
         "source": [
            "# å®šä¹‰ semantic function\n",
            "tell_joke_about = kernel.create_semantic_function(\"ç»™æˆ‘è®²ä¸ªå…³äº{{$input}}çš„ç¬‘è¯å§\")\n",
            "\n",
            "# çœ‹ç»“æœ\n",
            "print(tell_joke_about(\"Hello world\"))"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "<div class=\"alert alert-success\">\n",
            "<b>åˆ’é‡ç‚¹ï¼š</b>\n",
            "ç”¨æˆ‘ä»¬ç†Ÿæ‚‰çš„æ“ä½œç³»ç»Ÿæ¥ç±»æ¯”ï¼Œå¯ä»¥æ›´å¥½åœ°ç†è§£ SKã€‚\n",
            "<ol>\n",
            "<li>å¯åŠ¨æ“ä½œç³»ç»Ÿï¼š<code>kernel = sk.Kernel()</code></li>\n",
            "<li>å®‰è£…é©±åŠ¨ç¨‹åºï¼š<code>kernel.add_xxx_service()</code></li>\n",
            "<li>å®‰è£…åº”ç”¨ç¨‹åºï¼š<code>func = kernel.create_semantic_function()</code></li>\n",
            "<li>è¿è¡Œåº”ç”¨ç¨‹åºï¼š<code>func()</code></li>\n",
            "</ol>\n",
            "</div>\n",
            "\n",
            "åŸºäº SK å¼€å‘çš„ä¸»è¦å·¥ä½œæ˜¯å†™ã€Œåº”ç”¨ç¨‹åºã€ï¼Œä¹Ÿå°±æ˜¯ Plugins\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "jp-MarkdownHeadingCollapsed": true
         },
         "source": [
            "## Plugins\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "ç®€å•è¯´ï¼Œplugin å°±æ˜¯ä¸€ç»„å‡½æ•°çš„é›†åˆã€‚å®ƒå¯ä»¥åŒ…å«ä¸¤ç§å‡½æ•°ï¼š\n",
            "\n",
            "- Semantic Functions - è¯­ä¹‰å‡½æ•°ï¼Œæœ¬è´¨æ˜¯ Prompt Engineering\n",
            "- Native Functions - åŸç”Ÿå‡½æ•°ï¼Œç±»ä¼¼ OpenAI çš„ Function Calling\n",
            "\n",
            "å€¼å¾—ä¸€æçš„æ˜¯ï¼ŒSK çš„ plugin ä¼šå’Œ ChatGPTã€Bingã€Microsoft 365 é€šç”¨ã€‚ã€Œå¾ˆå¿«ã€ä½ ç”¨ SK å†™çš„ plugin å°±å¯ä»¥åœ¨è¿™äº›å¹³å°ä¸Šæ— ç¼ä½¿ç”¨äº†ã€‚è¿™äº›å¹³å°ä¸Šçš„ plugin ä¹Ÿå¯ä»¥é€šè¿‡ SK è¢«ä½ è°ƒç”¨ã€‚\n",
            "\n",
            "<div class=\"alert alert-warning\">\n",
            "<b>æ³¨æ„ï¼š</b>Plugins æœ€åˆå‘½åä¸º Skillsï¼Œåæ¥æ”¹ä¸º Pluginsã€‚ä½†æ˜¯æ— è®ºæ–‡æ¡£è¿˜æ˜¯ä»£ç ï¼Œéƒ½è¿˜æœ‰å¤§é‡çš„ã€ŒSkillã€é—ç•™ï¼Œé¢„è®¡åˆ° 1.0.0 å‘å¸ƒæ‰èƒ½æ¸…ç†å¹²å‡€ã€‚è§åˆ°åï¼Œå°±çŸ¥é“ä¸¤è€…æ˜¯ä¸€å›äº‹å°±å¥½\n",
            "</div>\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "jp-MarkdownHeadingCollapsed": true
         },
         "source": [
            "### Semantic Functions\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Semantic Functions æ˜¯çº¯ç”¨æ•°æ®ï¼ˆprompt + æè¿°ï¼‰å®šä¹‰çš„ï¼Œä¸éœ€è¦ç¼–å†™ä»»ä½•ä»£ç ã€‚æ‰€ä»¥å®ƒä¸ç¼–ç¨‹è¯­è¨€æ— å…³ï¼Œå¯ä»¥è¢«ä»»ä½•ç¼–ç¨‹è¯­è¨€è°ƒç”¨ã€‚\n",
            "\n",
            "ä¸€ä¸ªå…¸å‹çš„ semantic function åŒ…å«ä¸¤ä¸ªæ–‡ä»¶ï¼š\n",
            "\n",
            "- skprompt.txt: å­˜æ”¾ promptï¼Œå¯ä»¥åŒ…å«å‚æ•°ï¼Œè¿˜å¯ä»¥è°ƒç”¨å…¶å®ƒå‡½æ•°\n",
            "- config.json: å­˜æ”¾æè¿°ï¼ŒåŒ…æ‹¬å‡½æ•°åŠŸèƒ½ï¼Œå‚æ•°çš„æ•°æ®ç±»å‹ï¼Œä»¥åŠè°ƒç”¨å¤§æ¨¡å‹æ—¶çš„å‚æ•°\n",
            "\n",
            "ä¸¾ä¾‹ï¼šæŠŠ LangChain ã€Œç”Ÿæˆ Linux å‘½ä»¤ã€çš„ä¾‹å­ç”¨ SK å®ç°ã€‚\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "jp-MarkdownHeadingCollapsed": true
         },
         "source": [
            "#### skprompt.txt\n"
         ]
      },
      {
         "cell_type": "raw",
         "metadata": {},
         "source": [
            "å°†ç”¨æˆ·çš„æŒ‡ä»¤è½¬æ¢æˆ Linux å‘½ä»¤\n",
            "\n",
            "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
            "\n",
            "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}}\n",
            "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
            "\n",
            "Here is the output schema:\n",
            "```\n",
            "{\"properties\": {\"command\": {\"title\": \"Command\", \"description\": \"linux shellå‘½ä»¤å\", \"type\": \"string\"}, \"arguments\": {\"title\": \"Arguments\", \"description\": \"å‘½ä»¤çš„å‚æ•° (name:value)\", \"type\": \"object\", \"additionalProperties\": {\"type\": \"string\"}}}, \"required\": [\"command\", \"arguments\"]}\n",
            "```\n",
            "\n",
            "{{$input}}"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "jp-MarkdownHeadingCollapsed": true
         },
         "source": [
            "#### config.json\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "{\n",
            "    \"schema\": 1,\n",
            "    \"type\": \"completion\",\n",
            "    \"description\": \"å°†ç”¨æˆ·çš„æŒ‡ä»¤è½¬æ¢æˆ Linux å‘½ä»¤\",\n",
            "    \"completion\": {\n",
            "        \"max_tokens\": 256,\n",
            "        \"temperature\": 0,\n",
            "        \"top_p\": 0,\n",
            "        \"presence_penalty\": 0,\n",
            "        \"frequency_penalty\": 0\n",
            "    },\n",
            "    \"input\": {\n",
            "        \"parameters\": [\n",
            "            {\n",
            "                \"name\": \"input\",\n",
            "                \"description\": \"ç”¨æˆ·çš„æŒ‡ä»¤\",\n",
            "                \"defaultValue\": \"\"\n",
            "            }\n",
            "        ]\n",
            "    }\n",
            "}"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "ä¸Šé¢ä¸¤ä¸ªæ–‡ä»¶éƒ½åœ¨ [sk_samples/SamplePlugin/GenerateCommand](sk_samples/SamplePlugin/GenerateCommand/) ç›®å½•ä¸‹ã€‚\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "jp-MarkdownHeadingCollapsed": true
         },
         "source": [
            "#### è°ƒç”¨ Semantic Functions\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 8,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "{\n",
                  "  \"command\": \"date\",\n",
                  "  \"arguments\": {\n",
                  "    \"-s\": \"2023-04-01\"\n",
                  "  }\n",
                  "}\n"
               ]
            }
         ],
         "source": [
            "# åŠ è½½ semantic functionã€‚æ³¨æ„ç›®å½•ç»“æ„\n",
            "functions = kernel.import_semantic_skill_from_directory(\n",
            "    \"./sk_samples/\", \"SamplePlugin\")\n",
            "cli = functions[\"GenerateCommand\"]\n",
            "\n",
            "# çœ‹ç»“æœ\n",
            "print(cli(\"å°†ç³»ç»Ÿæ—¥æœŸè®¾ä¸º2023-04-01\"))"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "å®˜æ–¹æä¾›äº†å¤§é‡çš„ Semantic Functions å¯ä»¥å‚è€ƒï¼šhttps://github.com/microsoft/semantic-kernel/tree/main/samples/skills\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "jp-MarkdownHeadingCollapsed": true
         },
         "source": [
            "### Semantic Kernel Tools\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "è¿™æ˜¯ä¸ª VS Code çš„æ’ä»¶ï¼Œåœ¨ VS Code é‡Œå¯ä»¥ç›´æ¥åˆ›å»ºå’Œè°ƒè¯• Semantic Functionã€‚\n",
            "\n",
            "å®‰è£…åœ°å€ï¼šhttps://marketplace.visualstudio.com/items?itemName=ms-semantic-kernel.semantic-kernel\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "jp-MarkdownHeadingCollapsed": true
         },
         "source": [
            "### Native Functions\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "ç”¨ç¼–ç¨‹è¯­è¨€å†™çš„å‡½æ•°ï¼Œå¦‚æœç”¨ SK çš„ Native Function æ–¹å¼å®šä¹‰ï¼Œå°±èƒ½çº³å…¥åˆ° SK çš„ç¼–æ’ä½“ç³»ï¼Œå¯ä»¥è¢« Plannerã€å…¶å®ƒ plugin è°ƒç”¨ã€‚\n",
            "\n",
            "ä¸‹é¢ï¼Œå†™ä¸€ä¸ªè¿‡æ»¤æœ‰å®³ Linux å‘½ä»¤çš„å‡½æ•°ï¼Œå’Œ GenerateCommand ç»„åˆä½¿ç”¨ã€‚\n",
            "\n",
            "è¿™ä¸ªå‡½æ•°åæ˜¯ `harmful_command`ã€‚å¦‚æœè¾“å…¥çš„å‘½ä»¤æ˜¯æœ‰å®³çš„ï¼Œå°±è¿”å› `true`ï¼Œå¦åˆ™è¿”å› `false`ã€‚\n",
            "\n",
            "å®ƒä¹Ÿè¦æ”¾åˆ°ç›®å½•ç»“æ„ä¸­ï¼Œåœ¨ [sk_samples/SamplePlugin/SamplePlugin.py](sk_samples/SamplePlugin/SamplePlugin.py) é‡ŒåŠ å…¥ã€‚\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 9,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "{\n",
                  "  \"command\": \"rm\",\n",
                  "  \"arguments\": {\n",
                  "    \"-rf\": \"/\"\n",
                  "  }\n",
                  "}\n",
                  "true\n"
               ]
            }
         ],
         "source": [
            "# å› ä¸ºæ˜¯ä»£ç ï¼Œä¸æ˜¯æ•°æ®ï¼Œæ‰€ä»¥å¿…é¡» import\n",
            "from sk_samples.SamplePlugin.SamplePlugin import SamplePlugin\n",
            "\n",
            "# åŠ è½½ semantic function\n",
            "functions = kernel.import_semantic_skill_from_directory(\n",
            "    \"./sk_samples/\", \"SamplePlugin\")\n",
            "cli = functions[\"GenerateCommand\"]\n",
            "\n",
            "# åŠ è½½ native function\n",
            "functions = kernel.import_skill(SamplePlugin(), \"SamplePlugin\")\n",
            "harmful_command = functions[\"harmful_command\"]\n",
            "\n",
            "# çœ‹ç»“æœ\n",
            "command = cli(\"åˆ é™¤æ ¹ç›®å½•ä¸‹æ‰€æœ‰æ–‡ä»¶\")\n",
            "print(command)  # è¿™ä¸ª command å…¶å®æ˜¯ SKContext ç±»å‹\n",
            "print(harmful_command(context=command))  # æ‰€ä»¥è¦ä¼ å‚ç»™ context"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "jp-MarkdownHeadingCollapsed": true
         },
         "source": [
            "### ç”¨ SKContext å®ç°å¤šå‚æ•° Functions\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "å¦‚æœ Function éƒ½åªæœ‰ä¸€ä¸ªå‚æ•°ï¼Œé‚£ä¹ˆåªè¦æŠŠå‚æ•°å®šä¹‰ä¸º `{{$input}}`ï¼Œå°±å¯ä»¥æŒ‰å‰é¢çš„ä¾‹å­æ¥ä½¿ç”¨ï¼Œæ¯”è¾ƒç›´è§‚ã€‚`{{$input}}`ä¼šé»˜è®¤è¢«èµ‹å€¼ã€‚\n",
            "\n",
            "å¤šå‚æ•°æ—¶ï¼Œå°±ä¸èƒ½ç”¨é»˜è®¤æœºåˆ¶äº†ï¼Œéœ€è¦å®šä¹‰ `SKContext` ç±»å‹çš„å˜é‡ã€‚\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 10,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "66560.0\n"
               ]
            }
         ],
         "source": [
            "# å› ä¸ºæ˜¯ä»£ç ï¼Œä¸æ˜¯æ•°æ®ï¼Œæ‰€ä»¥å¿…é¡» import\n",
            "from sk_samples.SamplePlugin.SamplePlugin import SamplePlugin\n",
            "\n",
            "# åŠ è½½ native function\n",
            "functions = kernel.import_skill(SamplePlugin(), \"SamplePlugin\")\n",
            "add = functions[\"add\"]\n",
            "\n",
            "# çœ‹ç»“æœ\n",
            "context = kernel.create_new_context()\n",
            "context[\"number1\"] = 1024\n",
            "context[\"number2\"] = 65536\n",
            "total = add(context=context)\n",
            "print(total)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "jp-MarkdownHeadingCollapsed": true
         },
         "source": [
            "### å†…ç½® Plugins\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "SK å†…ç½®äº†è‹¥å¹²å¥½ç”¨çš„ pluginï¼Œä½†å› ä¸ºå†å²åŸå› ï¼Œå®ƒä»¬å« skillâ€¦â€¦\n",
            "\n",
            "åŠ è½½æ–¹æ³•ï¼š\n",
            "\n",
            "```python\n",
            "from semantic_kernel.core_skills import SkillName\n",
            "```\n",
            "\n",
            "å®ƒä»¬æ˜¯ï¼š\n",
            "\n",
            "- [`ConversationSummarySkill`](https://github.com/microsoft/semantic-kernel/blob/main/python/semantic_kernel/core_skills/conversation_summary_skill.py) - ç”Ÿæˆå¯¹è¯çš„æ‘˜è¦\n",
            "- [`FileIOSkill`](https://github.com/microsoft/semantic-kernel/blob/main/python/semantic_kernel/core_skills/file_io_skill.py) - è¯»å†™æ–‡ä»¶\n",
            "- [`HttpSkill`](https://github.com/microsoft/semantic-kernel/blob/main/python/semantic_kernel/core_skills/http_skill.py) - å‘å‡º HTTP è¯·æ±‚ï¼Œæ”¯æŒ GETã€POSTã€PUT å’Œ DELETE\n",
            "- [`MathSkill`](https://github.com/microsoft/semantic-kernel/blob/main/python/semantic_kernel/core_skills/math_skill.py) - åŠ æ³•å’Œå‡æ³•è®¡ç®—\n",
            "- [`TextMemorySkill`](https://github.com/microsoft/semantic-kernel/blob/main/python/semantic_kernel/core_skills/text_memory_skill.py) - ä¿å­˜æ–‡æœ¬åˆ° memory ä¸­ï¼Œå¯ä»¥å¯¹å…¶åšå‘é‡æ£€ç´¢\n",
            "- [`TextSkill`](https://github.com/microsoft/semantic-kernel/blob/main/python/semantic_kernel/core_skills/text_skill.py) - æŠŠæ–‡æœ¬å…¨éƒ¨è½¬ä¸ºå¤§å†™æˆ–å°å†™ï¼Œå»æ‰å¤´å°¾çš„ç©ºæ ¼ï¼ˆtrimï¼‰\n",
            "- [`TimeSkill`](https://github.com/microsoft/semantic-kernel/blob/main/python/semantic_kernel/core_skills/time_skill.py) - è·å–å½“å‰æ—¶é—´åŠç”¨å¤šç§æ ¼å¼è·å–æ—¶é—´å‚æ•°\n",
            "- [`WaitSkill`](https://github.com/microsoft/semantic-kernel/blob/main/python/semantic_kernel/core_skills/wait_skill.py) - ç­‰å¾…æŒ‡å®šçš„æ—¶é—´\n",
            "- [`WebSearchEngineSkill`](https://github.com/microsoft/semantic-kernel/blob/main/python/semantic_kernel/core_skills/web_search_engine_skill.py) - åœ¨äº’è”ç½‘ä¸Šæœç´¢ç»™å®šçš„æ–‡æœ¬\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "jp-MarkdownHeadingCollapsed": true
         },
         "source": [
            "## Memory\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "SK çš„ memory ä½¿ç”¨éå¸¸ç®€å•ï¼š\n",
            "\n",
            "1. ç”¨ `kernel.add_text_embedding_generation_service()` æ·»åŠ ä¸€ä¸ªæ–‡æœ¬å‘é‡ç”ŸæˆæœåŠ¡\n",
            "2. ç”¨ `kernel.register_memory_store()` æ³¨å†Œä¸€ä¸ª memory storeï¼Œå¯ä»¥æ˜¯å†…å­˜ã€æ–‡ä»¶ã€å‘é‡æ•°æ®åº“ç­‰\n",
            "3. ç”¨ `kernel.memory.save_information_async()` ä¿å­˜ä¿¡æ¯åˆ° memory store\n",
            "4. ç”¨ `kernel.memory.search_async()` æœç´¢ä¿¡æ¯\n",
            "\n",
            "ä½¿ç”¨ ChatALL çš„ README.md åšæ•°æ®ï¼Œä½¿ç”¨å†…å­˜ä½œä¸º memory storeï¼Œæˆ‘ä»¬æ¼”ç¤ºä¸‹åŸºäºæ–‡æ¡£å¯¹è¯ã€‚\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "jp-MarkdownHeadingCollapsed": true
         },
         "source": [
            "### åˆå§‹åŒ– Embedding\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 11,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "<semantic_kernel.kernel.Kernel at 0x1154f5650>"
                  ]
               },
               "execution_count": 11,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "import semantic_kernel as sk\n",
            "from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion, OpenAITextEmbedding\n",
            "import os\n",
            "\n",
            "# åŠ è½½ .env åˆ°ç¯å¢ƒå˜é‡\n",
            "from dotenv import load_dotenv, find_dotenv\n",
            "_ = load_dotenv(find_dotenv())\n",
            "\n",
            "# åˆ›å»º semantic kernel\n",
            "kernel = sk.Kernel()\n",
            "\n",
            "# é…ç½® OpenAI æœåŠ¡\n",
            "api_key = os.getenv('OPENAI_API_KEY')\n",
            "endpoint = os.getenv('OPENAI_API_BASE')\n",
            "model = OpenAIChatCompletion(\n",
            "    \"gpt-3.5-turbo\", api_key, endpoint=endpoint)\n",
            "\n",
            "# æŠŠ LLM æœåŠ¡åŠ å…¥ kernel\n",
            "# å¯ä»¥åŠ å¤šä¸ªã€‚ç¬¬ä¸€ä¸ªåŠ å…¥çš„ä¼šè¢«é»˜è®¤ä½¿ç”¨ï¼Œéé»˜è®¤çš„è¦è¢«æŒ‡å®šä½¿ç”¨\n",
            "kernel.add_text_completion_service(\"my-gpt3\", model)\n",
            "\n",
            "# æ·»åŠ  embedding æœåŠ¡\n",
            "kernel.add_text_embedding_generation_service(\n",
            "    \"ada\", OpenAITextEmbedding(\"text-embedding-ada-002\", api_key, endpoint=endpoint))"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "jp-MarkdownHeadingCollapsed": true
         },
         "source": [
            "### æ–‡æœ¬å‘é‡åŒ–\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 12,
         "metadata": {},
         "outputs": [],
         "source": [
            "from semantic_kernel.text import split_markdown_lines\n",
            "\n",
            "# ä½¿ç”¨å†…å­˜åš memory store\n",
            "kernel.register_memory_store(memory_store=sk.memory.VolatileMemoryStore())\n",
            "\n",
            "# è¯»å–æ–‡ä»¶å†…å®¹\n",
            "with open('ChatALL.md', 'r') as f:\n",
            "    # with open('sk_samples/SamplePlugin/SamplePlugin.py', 'r') as f:\n",
            "    content = f.read()\n",
            "\n",
            "# å°†æ–‡ä»¶å†…å®¹åˆ†ç‰‡ï¼Œå•ç‰‡æœ€å¤§ 100 tokenï¼ˆæ³¨æ„ï¼šSK çš„ text split åŠŸèƒ½ç›®å‰å¯¹ä¸­æ–‡æ”¯æŒä¸å¦‚å¯¹è‹±æ–‡æ”¯æŒå¾—å¥½ï¼‰\n",
            "lines = split_markdown_lines(content, 100)\n",
            "\n",
            "# å°†åˆ†ç‰‡åçš„å†…å®¹ï¼Œå­˜å…¥å†…å­˜\n",
            "for index, line in enumerate(lines):\n",
            "    await kernel.memory.save_information_async(\"chatall\", id=index, text=line)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "jp-MarkdownHeadingCollapsed": true
         },
         "source": [
            "### å‘é‡æœç´¢\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 13,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "æ‹¥æœ‰å¯ä»¥è®¿é—®è¿™äº› AI çš„å¸å·ï¼Œæˆ– API tokenã€‚\n",
                  "2. ä¸ AI ç½‘ç«™æœ‰å¯é çš„ç½‘ç»œè¿æ¥ã€‚\n",
                  "\n",
                  "## ä¸‹è½½ / å®‰è£…\n",
                  "\n",
                  "ä» https://github.com/sunner/ChatALL/releases ä¸‹è½½\n",
                  "\n",
                  "### Windows ç³»ç»Ÿ\n",
                  "\n",
                  "ç›´æ¥ä¸‹è½½ \\*-win.exe å®‰è£…æ–‡ä»¶å¹¶è¿è¡Œä¹‹ã€‚\n",
                  "\n",
                  "### macOS ç³»ç»Ÿ\n",
                  "\n",
                  "å¯¹äºè‹¹æœç¡…èŠ¯ç‰‡ Macï¼ˆM1ï¼ŒM2 CPUï¼‰ï¼Œè¯·ä¸‹è½½ \\*-mac-arm64.\n"
               ]
            }
         ],
         "source": [
            "result = await kernel.memory.search_async(\"chatall\", \"ChatALLæ€ä¹ˆä¸‹è½½ï¼Ÿ\")\n",
            "print(result[0].text)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "jp-MarkdownHeadingCollapsed": true
         },
         "source": [
            "## Pipeline / Chain\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "SK æ›´æƒ³ç”¨ pipeline æ¥æè¿° LangChain ä¸­ chain çš„æ¦‚å¿µï¼Œå¤§æ¦‚å› ä¸º pipeline è¿™ä¸ªè¯æ›´æ“ä½œç³»ç»Ÿå§ã€‚ä½† chain è¿™ä¸ªåè¯å½±å“åŠ›å¤ªå¤§ï¼Œæ‰€ä»¥ SK æ—¶ä¸æ—¶ä¹Ÿä¼šç”¨å®ƒã€‚\n",
            "\n",
            "ä½†æ˜¯ï¼ŒSK æ²¡æœ‰åœ¨ä»£ç é‡Œå®šä¹‰ä»€ä¹ˆæ˜¯ pipelineï¼Œå®ƒå¹¶ä¸æ˜¯ä¸€ä¸ªç±»ï¼Œæˆ–è€…å‡½æ•°ä»€ä¹ˆçš„ã€‚å®ƒæ˜¯è´¯å½»æ•´ä¸ª kernel çš„ä¸€ä¸ªæ¦‚å¿µã€‚\n",
            "\n",
            "å½“ä¸€ä¸ª kernel æ·»åŠ äº† LLMã€memoryã€functionsï¼Œæˆ‘ä»¬å†™ä¸‹çš„ functions ä¹‹é—´çš„ç»„åˆè°ƒç”¨ï¼Œå°±æ˜¯ä¸ª pipeline äº†ã€‚\n",
            "\n",
            "å¦‚æœéœ€è¦å¤šæ¡ pipelineï¼Œå°±å®šä¹‰å¤šä¸ª kernelã€‚\n",
            "\n",
            "<div class=\"alert alert-block alert-info\">\n",
            "<b>æ€è€ƒï¼š</b>LangChain å®šä¹‰äº†å¥½å‡ ç§ Chainï¼›SK åªæ˜¯ç”¨ kernel æŠŠæŠ½è±¡åŠŸèƒ½ç»„åˆèµ·æ¥ï¼Œpipeline çš„è¿‡ç¨‹å®Œå…¨äº¤ç»™å¼€å‘è€…è‡ªå·±å®šä¹‰ã€‚ä½ è§‰å¾—å“ªç§è®¾è®¡æ›´å¥½ï¼Ÿ\n",
            "</div>\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "ç°åœ¨ç”¨ pipeline æ€æƒ³æŠŠå¯¹è¯å¼æœç´¢ ChatALL çš„ README.md åŠŸèƒ½åšå®Œæ•´ã€‚\n",
            "\n",
            "åœ¨è‡ªå®šä¹‰çš„ Semantic Function ä¸­ï¼ŒåµŒå¥—è°ƒç”¨å†…ç½®çš„ `TextMemorySkill`ã€‚\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 14,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "ä» https://github.com/sunner/ChatALL/releases ä¸‹è½½å®‰è£…æ–‡ä»¶ã€‚å¯¹äºWindowsç³»ç»Ÿï¼Œä¸‹è½½\\*-win.exeæ–‡ä»¶å¹¶è¿è¡Œï¼›å¯¹äºè‹¹æœç¡…èŠ¯ç‰‡Macç³»ç»Ÿï¼Œè¯·ä¸‹è½½\\*-mac-arm64æ–‡ä»¶ã€‚\n"
               ]
            }
         ],
         "source": [
            "# å¯¼å…¥å†…ç½®çš„ `TextMemorySkill`ã€‚ä¸»è¦ä½¿ç”¨å®ƒçš„ `recall()`\n",
            "kernel.import_skill(sk.core_skills.TextMemorySkill())\n",
            "\n",
            "# ç›´æ¥åœ¨ä»£ç é‡Œåˆ›å»º semantic functionã€‚çœŸå®å·¥ç¨‹ä¸å»ºè®®è¿™ä¹ˆåš\n",
            "# é‡Œé¢è°ƒç”¨äº† `recall()`\n",
            "sk_prompt = \"\"\"\n",
            "åŸºäºä¸‹é¢çš„èƒŒæ™¯ä¿¡æ¯å›ç­”é—®é¢˜ã€‚å¦‚æœèƒŒæ™¯ä¿¡æ¯ä¸ºç©ºï¼Œæˆ–è€…å’Œé—®é¢˜ä¸ç›¸å…³ï¼Œè¯·å›ç­”\"æˆ‘ä¸çŸ¥é“\"ã€‚\n",
            "\n",
            "[èƒŒæ™¯ä¿¡æ¯å¼€å§‹]\n",
            "{{recall $input}}\n",
            "[èƒŒæ™¯ä¿¡æ¯ç»“æŸ]\n",
            "\n",
            "é—®é¢˜ï¼š{{$input}}\n",
            "å›ç­”ï¼š\n",
            "\"\"\"\n",
            "ask = kernel.create_semantic_function(sk_prompt)\n",
            "\n",
            "# æé—®\n",
            "context = kernel.create_new_context()\n",
            "context[sk.core_skills.TextMemorySkill.COLLECTION_PARAM] = \"chatall\"\n",
            "context[sk.core_skills.TextMemorySkill.RELEVANCE_PARAM] = 0.8\n",
            "context[\"input\"] = \"ChatALL æ€ä¹ˆä¸‹è½½ï¼Ÿ\"\n",
            "result = ask(context=context)\n",
            "print(result)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "ç”¨æ›´ pipeline çš„æ–¹å¼å®ç°åŒæ ·çš„åŠŸèƒ½\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 15,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "ä» https://github.com/sunner/ChatALL/releases ä¸‹è½½å®‰è£…æ–‡ä»¶ï¼Œå¹¶æ ¹æ®æ“ä½œç³»ç»Ÿé€‰æ‹©å¯¹åº”çš„æ–‡ä»¶è¿›è¡Œä¸‹è½½ã€‚å¯¹äºWindowsç³»ç»Ÿï¼Œä¸‹è½½\\*-win.exeæ–‡ä»¶å¹¶è¿è¡Œï¼›å¯¹äºè‹¹æœç¡…èŠ¯ç‰‡Macç³»ç»Ÿï¼Œè¯·ä¸‹è½½\\*-mac-arm64æ–‡ä»¶ã€‚\n"
               ]
            }
         ],
         "source": [
            "# å¯¼å…¥å†…ç½®çš„ `TextMemorySkill`ã€‚ä¸»è¦ä½¿ç”¨å®ƒçš„ `recall()`\n",
            "text_memory_functions = kernel.import_skill(sk.core_skills.TextMemorySkill())\n",
            "recall = text_memory_functions[\"recall\"]\n",
            "\n",
            "# ç›´æ¥åœ¨ä»£ç é‡Œåˆ›å»º semantic functionã€‚çœŸå®å·¥ç¨‹ä¸å»ºè®®è¿™ä¹ˆåš\n",
            "sk_prompt = \"\"\"\n",
            "åŸºäºä¸‹é¢çš„èƒŒæ™¯ä¿¡æ¯å›ç­”é—®é¢˜ã€‚å¦‚æœèƒŒæ™¯ä¿¡æ¯ä¸ºç©ºï¼Œæˆ–è€…å’Œé—®é¢˜ä¸ç›¸å…³ï¼Œè¯·å›ç­”\"æˆ‘ä¸çŸ¥é“\"ã€‚\n",
            "\n",
            "[èƒŒæ™¯ä¿¡æ¯å¼€å§‹]\n",
            "{{$input}}\n",
            "[èƒŒæ™¯ä¿¡æ¯ç»“æŸ]\n",
            "\n",
            "é—®é¢˜ï¼š{{$user_input}}\n",
            "å›ç­”ï¼š\n",
            "\"\"\"\n",
            "ask = kernel.create_semantic_function(sk_prompt)\n",
            "\n",
            "# å‡†å¤‡ context\n",
            "context = kernel.create_new_context()\n",
            "context[sk.core_skills.TextMemorySkill.COLLECTION_PARAM] = \"chatall\"\n",
            "context[sk.core_skills.TextMemorySkill.RELEVANCE_PARAM] = 0.8\n",
            "context[\"input\"] = \"ChatALL æ€ä¹ˆä¸‹è½½ï¼Ÿ\"\n",
            "context[\"user_input\"] = \"ChatALL æ€ä¹ˆä¸‹è½½ï¼Ÿ\"\n",
            "\n",
            "# pipeline\n",
            "result = await kernel.run_async(recall, ask, input_context=context)\n",
            "print(result)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Planner\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "SK çš„ planner æ¦‚å¿µä¸Šå¯¹æ ‡ LangChain çš„ agentï¼Œä½†åšå¾—æ¯”è¾ƒç®€å•ï¼Œè¿˜æ¯”è¾ƒåˆæ­¥ã€‚\n",
            "\n",
            "SK Python æä¾›äº†å››ç§ plannerï¼š\n",
            "\n",
            "1. `SequentialPlanner`\n",
            "   - åˆ¶å®šåŒ…å«ä¸€ç³»åˆ—æ­¥éª¤çš„è®¡åˆ’ï¼Œè¿™äº›æ­¥éª¤é€šè¿‡è‡ªå®šä¹‰ç”Ÿæˆçš„è¾“å…¥å’Œè¾“å‡ºå˜é‡ç›¸äº’è¿æ¥\n",
            "   - æ ¸å¿ƒ promptï¼šhttps://github.com/microsoft/semantic-kernel/blob/main/python/semantic_kernel/planning/sequential_planner/Skills/SequentialPlanning/skprompt.txt\n",
            "   - å®˜æ–¹ä¾‹ç¨‹ï¼šhttps://github.com/microsoft/semantic-kernel/blob/main/python/samples/kernel-syntax-examples/sequential_planner.py\n",
            "2. `ActionPlanner`\n",
            "   - ç±»ä¼¼ OpenAI Function Callingï¼Œä» kernel ä¸­å·²æ³¨å†Œçš„æ‰€æœ‰ plugin ä¸­æ‰¾åˆ°ä¸€ä¸ªè¯¥æ‰§è¡Œçš„å‡½æ•°\n",
            "   - æ ¸å¿ƒ promptï¼šhttps://github.com/microsoft/semantic-kernel/blob/main/python/semantic_kernel/planning/action_planner/skprompt.txt\n",
            "   - å®˜æ–¹ä¾‹ç¨‹ï¼šhttps://github.com/microsoft/semantic-kernel/blob/main/python/samples/kernel-syntax-examples/action_planner.py\n",
            "3. `StepwisePlanner`\n",
            "   - æ¯æ‰§è¡Œå®Œä¸€æ­¥ï¼Œéƒ½åšä¸€ä¸‹å¤ç›˜\n",
            "   - å·²å‘å¸ƒã€‚åªè¾“å‡º actionï¼Œä¸æ‰§è¡Œ\n",
            "   - æ ¸å¿ƒ promptï¼šhttps://github.com/microsoft/semantic-kernel/blob/main/python/semantic_kernel/planning/stepwise_planner/Skills/StepwiseStep/skprompt.txt\n",
            "4. `BasicPlanner`\n",
            "   - **ä¸å»ºè®®ä½¿ç”¨**ã€‚æŠŠä»»åŠ¡æ‹†è§£ï¼Œè‡ªåŠ¨è°ƒç”¨å„ä¸ªå‡½æ•°ï¼Œå®Œæˆä»»åŠ¡ã€‚å®ƒåªæ˜¯ä¸ªç”¨äºåŸºç¡€éªŒè¯çš„åŠŸèƒ½ï¼Œæœ€ç»ˆä¼šè¢« `SequentialPlanner` æ›¿ä»£\n",
            "   - æ ¸å¿ƒ promptï¼šhttps://github.com/microsoft/semantic-kernel/blob/main/python/semantic_kernel/planning/basic_planner.py#L27-L123\n",
            "\n",
            "ä½¿ç”¨ planner çš„æ­¥éª¤éå¸¸ç®€å•ï¼š\n",
            "\n",
            "1. æŠŠ plugin æ³¨å†Œåˆ° kernel\n",
            "2. æŠŠ kernel å½“å‚æ•°å®ä¾‹åŒ–æŸä¸ª planner\n",
            "3. è°ƒç”¨ planner çš„ `create_plan_async()` æ–¹æ³•è·å¾— plan\n",
            "4. è°ƒç”¨ plan çš„ `invoke_async()` æ–¹æ³•æ‰§è¡Œ plan\n",
            "\n",
            "(æ³¨æ„ï¼Œä¸åŒ planner æ¥å£å¹¶ä¸ä¸€è‡´ï¼Œä¸èƒ½ç®€å•å¹³æ›¿)\n",
            "\n",
            "ä¸‹é¢ï¼ŒæŠŠæŸ¥å‘¨æ°ä¼¦çš„ç”Ÿæ—¥æ˜¯æ˜ŸæœŸå‡ ï¼Œç”¨ `SequentialPlanner` å†åšä¸€éã€‚\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 1,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Step: 0\n",
                  "Description: Performs a web search for a given query\n",
                  "Function: WebSearch.searchAsync\n",
                  "  Output:\n",
                  " ['å…³æ³¨. å±•å¼€å…¨éƒ¨. é˜³å†1979å¹´1æœˆ18æ—¥æ˜ŸæœŸå›› å†œå† å·±æœªå¹´ å†œå†12æœˆ20æ—¥ å§“å:å‘¨æ°ä¼¦ è‹±æ–‡å:Jay chou å‡ºç”Ÿï¼š1979å¹´1æœˆ18æ—¥ å­¦å†ï¼šæ·¡æ±Ÿä¸­å­¦éŸ³ä¹ç§‘ ç”Ÿè‚–:é©¬ è¡€å‹ï¼šOå‹ æ˜Ÿåº§ï¼šé­”ç¾¯åº§ èº«é«˜ï¼š175cm ä½“é‡ï¼š60kg ä¸“é•¿ï¼šå†™æ­Œã€ä½œè¯ã€æ‰“çƒ ä¸“ç²¾ä¹å™¨ï¼šé’¢ç´ã€å¤§æç´ã€å‰ä»– ...']\n",
                  "Step: 1\n",
                  "Description: è¾“å‡º input ä¸­å‡ºç°çš„ç¬¬ä¸€ä¸ªæ—¥æœŸæ˜¯æ˜ŸæœŸå‡ \n",
                  "Function: DatePlugin.DayOfWeek\n",
                  "  Output:\n",
                  " æ˜ŸæœŸå››\n",
                  "æ˜ŸæœŸå››\n"
               ]
            }
         ],
         "source": [
            "from semantic_kernel.core_skills import WebSearchEngineSkill\n",
            "from semantic_kernel.connectors.search_engine import BingConnector\n",
            "from semantic_kernel.planning import SequentialPlanner\n",
            "import semantic_kernel as sk\n",
            "from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion\n",
            "import os\n",
            "\n",
            "# åŠ è½½ .env åˆ°ç¯å¢ƒå˜é‡\n",
            "from dotenv import load_dotenv, find_dotenv\n",
            "_ = load_dotenv(find_dotenv())\n",
            "\n",
            "# åˆ›å»º semantic kernel\n",
            "kernel = sk.Kernel()\n",
            "\n",
            "# é…ç½® OpenAI æœåŠ¡\n",
            "api_key = os.getenv('OPENAI_API_KEY')\n",
            "endpoint = os.getenv('OPENAI_API_BASE')\n",
            "model = OpenAIChatCompletion(\n",
            "    \"gpt-3.5-turbo\", api_key, endpoint=endpoint)\n",
            "\n",
            "# æŠŠ LLM æœåŠ¡åŠ å…¥ kernel\n",
            "# å¯ä»¥åŠ å¤šä¸ªã€‚ç¬¬ä¸€ä¸ªåŠ å…¥çš„ä¼šè¢«é»˜è®¤ä½¿ç”¨ï¼Œéé»˜è®¤çš„è¦è¢«æŒ‡å®šä½¿ç”¨\n",
            "kernel.add_text_completion_service(\"my-gpt4\", model)\n",
            "\n",
            "# å¯¼å…¥æœç´¢ plugin\n",
            "connector = BingConnector(api_key=os.getenv(\"BING_API_KEY\"))\n",
            "kernel.import_skill(WebSearchEngineSkill(connector), \"WebSearch\")\n",
            "\n",
            "# ä½¿ç”¨ DayOfWeek()\n",
            "# kernel.import_semantic_skill_from_directory(\"./sk_samples/\", \"SamplePlugin\")\n",
            "\n",
            "sk_prompt = \"\"\"\n",
            "ä»¥ä¸‹å†…å®¹é‡Œå‡ºç°çš„ç¬¬ä¸€ä¸ªæ—¥æœŸæ˜¯æ˜ŸæœŸå‡ ï¼Ÿåªè¾“å‡ºæ˜ŸæœŸå‡ \n",
            "\n",
            "{{$input}}\n",
            "\"\"\"\n",
            "kernel.create_semantic_function(\n",
            "    sk_prompt, \"DayOfWeek\", \"DatePlugin\", \"è¾“å‡º input ä¸­å‡ºç°çš„ç¬¬ä¸€ä¸ªæ—¥æœŸæ˜¯æ˜ŸæœŸå‡ \")\n",
            "\n",
            "# åˆ›å»º planner\n",
            "planner = SequentialPlanner(kernel)\n",
            "\n",
            "# å¼€å§‹\n",
            "ask = \"å‘¨æ°ä¼¦çš„ç”Ÿæ—¥æ˜¯æ˜ŸæœŸå‡ ï¼Ÿ\"\n",
            "plan = await planner.create_plan_async(goal=ask)\n",
            "\n",
            "result = await plan.invoke_async(logger=print)\n",
            "\n",
            "# æ‰“å°æ­¥éª¤ç”¨æ¥è°ƒè¯•\n",
            "for index, step in enumerate(plan._steps):\n",
            "    print(\"Step:\", index)\n",
            "    print(\"Description:\", step.description)\n",
            "    print(\"Function:\", step.skill_name + \".\" + step._function.name)\n",
            "    if len(step._outputs) > 0:\n",
            "        print(\"  Output:\\n\", str.replace(\n",
            "            result[step._outputs[0]], \"\\n\", \"\\n  \"))\n",
            "\n",
            "\n",
            "print(result)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## ç”¨ Prompt Flow è°ƒè¯•å’Œè¯„ä¼°\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "[Prompt flow](https://github.com/microsoft/promptflow) å¯ä»¥å¯¹æ ‡ LangSmithï¼Œä½†åŒºåˆ«æŒºå¤§ã€‚\n",
            "\n",
            "- æ˜¯ä¸ª VS Code æ’ä»¶ + å‘½ä»¤è¡Œå·¥å…·\n",
            "- å¯ä»¥å’Œ SK é…åˆï¼Œä¹Ÿå¯ä»¥ç‹¬ç«‹ä½¿ç”¨\n",
            "- å¯è§†åŒ– flow ç»„åˆ prompt å’Œä»£ç ï¼Œè°ƒè¯•å‚æ•°ï¼Œç”¨æ•°æ®é›†è¯„ä¼°æ•ˆæœ\n",
            "- ä»£ç å¯ç›´æ¥éƒ¨ç½²åˆ° Azure\n",
            "- [flows/chat/](flows/chat/) æ¼”ç¤ºäº†çº¯é  prompt flow æ‹¼æ¥ï¼Œå®ç°å’Œ LLM å¯¹è¯ï¼Œä½†æ¯æ¬¡çš„è¾“å‡ºéƒ½ç”¨ LLM åšæ‘˜è¦ï¼Œä»¥èŠ‚çº¦é˜…è¯»æ—¶é—´\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "# LangChain å’Œ Semantic Kernel æ€ä¹ˆé€‰ï¼Ÿ\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "<div class=\"alert alert-success\">\n",
            "<b>åˆ’é‡ç‚¹ï¼š</b>\n",
            "<ol>\n",
            "<li>ä¸¤è€…éƒ½å€¼å¾—å­¦</li>\n",
            "<li>C#ã€Java åªèƒ½ç”¨ SKï¼ŒJavaScript åªèƒ½ç”¨ LangChain</li>\n",
            "<li>åšåŸå‹ï¼Œé¦–é€‰ LangChainã€‚åŠŸèƒ½å¤šï¼Œå¼€å‘å¿«</li>\n",
            "<li>åšäº§å“ï¼Œè¿˜æ˜¯ SK é•¿æœŸæ›´å¯ä¾èµ–</li>\n",
            "</ol>\n",
            "</div>\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "å¤šè¯´ä¸¤å¥ï¼š\n",
            "\n",
            "- LC å’Œ SK çš„åŒºåˆ«å³æ˜¯åˆ›ä¸šå’Œå¤§å‚çš„åŒºåˆ«ï¼Œä¹Ÿæ˜¯ç®—æ³•æ€ç»´å’Œå·¥ç¨‹æ€ç»´çš„åŒºåˆ«\n",
            "- è®ºæ–‡ä¸Šçš„ç†è®ºï¼Œä»¿çœŸå‡ºçš„ç®—æ³•ï¼Œè½åˆ°å·¥ç¨‹é¡¹ç›®ï¼Œå¸¸å¸¸éœ€è¦é‡å†™ã€‚è¿™ä¸æ˜¯ Python çš„é—®é¢˜\n",
            "- ç®—æ³•ç§‘å­¦å®¶ä¸æ‡‚å·¥ç¨‹ï¼Œè½¯ä»¶å·¥ç¨‹å¸ˆä¸æ‡‚ç®—æ³•ï¼Œè¿™æ˜¯ AI å‰§çƒˆå‘å±•å¸¦æ¥çš„çœŸç©ºåœ°å¸¦\n",
            "- è°æ¥å¡«è¡¥ï¼Ÿ\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## å…¶å®ƒå€¼å¾—å…³æ³¨çš„æ¡†æ¶\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### LlamaIndex\n",
            "\n",
            "[LlamaIndex](https://github.com/run-llama/llama_index) æ˜¯ä¸€ä¸ªå»ºé€  LLM åº”ç”¨çš„**æ•°æ®æ¡†æ¶**\n",
            "\n",
            "- GitHub 22k+ stars\n",
            "- ä¸“é—¨é’ˆå¯¹æœç´¢ã€æ£€ç´¢ç±» LLM åº”ç”¨ä¼˜åŒ–ï¼Œæ€§èƒ½ä¸é”™\n",
            "- æ¥å£ç®€å•ç›´æ¥ï¼Œæ˜“äºä¸Šæ‰‹\n",
            "- å¤–éƒ¨æ•°æ®çš„å¯¹æ¥æå…¶æ–¹ä¾¿ï¼šhttps://llamahub.ai/\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### MetaGPT\n",
            "\n",
            "[MetaGPT](https://github.com/geekan/MetaGPT) å›½å†…å…¬å¸å¼€å‘çš„å¤š Agent æ¡†æ¶\n",
            "\n",
            "- GitHub 27k+ stars\n",
            "- å¹¶ä¸æ˜¯ AI ç¼–ç¨‹å·¥å…·ï¼Œè€Œæ˜¯ä¸ªå¼€å‘æ¡†æ¶\n",
            "- å¤š Agent çš„æ¦‚å¿µéå¸¸è¶…å‰ã€‚è™½ç„¶å®ç”¨æ€§è¿˜ä¸è¡Œï¼Œä½†å€¼å¾—å…³æ³¨\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## å®ƒä»¬éƒ½å¯ä»¥ç»„åˆä½¿ç”¨\n",
            "\n",
            "å„å–å…¶é•¿ï¼Œä½†å¯¹æˆ‘ä»¬çš„è¦æ±‚æ›´é«˜ï¼Œå…ä¸äº†è¦è¯»æºä»£ç æ¥åˆ†æå®ƒä»¬ï¼Œæ‰¾åˆ°æœ€ä½³çš„ç»„åˆç­–ç•¥ï¼ˆè¿‡ç¨‹ä¸­ï¼Œå¯èƒ½ä¼šå‘ç°ï¼Œæœ‰äº›éƒ¨åˆ†è‡ªå·±åšæ›´å¥½ï¼‰ã€‚\n",
            "\n",
            "<div class=\"alert alert-success\">\n",
            "ç»„åˆå¥—è·¯ï¼š\n",
            "<ol>\n",
            "<li>ç”¨ SK æ­æ¡†æ¶ï¼Œç”¨å®ƒçš„ Connectors å’Œ Plugins èƒ½åŠ›</li>\n",
            "<li>ç”¨ LangChain çš„å„ç§å°å·¥å…·åšå±€éƒ¨å¤„ç†ï¼Œæ¯”å¦‚ TextSplitterã€OutputParser</li>\n",
            "<li>ç”¨ LlamaIndex å¯¹æ¥å¤–éƒ¨æ•°æ®</li>\n",
            "<li>ç”¨ Prompt Flow è°ƒè¯•å’Œè¯„ä¼°</li>\n",
            "<li>ç”¨ LangSmith ç›‘è§† LLM æµé‡</li>\n",
            "<li>è‡ªå»ºè‡ªå·±çš„ agentï¼ˆç‰¹å®šåœºæ™¯çš„ agent ä¸€å®šä¸æ˜¯é€šç”¨çš„ï¼‰</li>\n",
            "</ol>\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "jp-MarkdownHeadingCollapsed": true
         },
         "source": [
            "# å‚ä¸å¼€æºè½¯ä»¶å¼€å‘ï¼Œæ­£å½“æ—¶\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "<div class=\"alert alert-warning\">\n",
            "<b>ä¸ºä»€ä¹ˆè¦ä¸ºå¼€æºè½¯ä»¶è´¡çŒ®ä»£ç ï¼š</b>\n",
            "<li>è¿™æ˜¯ä¸€ä¸ªäºå·±ã€äºä»–äººéƒ½æœ‰å¥½å¤„çš„å…±äº«äº‹ä¸š</li>\n",
            "<li>å¤§æ¨¡å‹ç›¸å…³çš„å¼€æºè½¯ä»¶éƒ½åœ¨èµ·æ­¥é˜¶æ®µï¼Œæœ‰å¾ˆå¤šä½å‚çš„æœå®</li>\n",
            "<li>LangChain å’Œ SK å¯¹å›½äº§å¤§æ¨¡å‹æ”¯æŒæœ‰é™ï¼Œè¿™æ˜¯å¥½æœºä¼š</li>\n",
            "<li>è¿‡ç¨‹ä¸­èƒ½å¯¹æœºç†äº†è§£æ›´æ·±</li>\n",
            "<li>åœ¨ç®€å†ä¸­æ˜¯ä¸ªäº®è‰²</li>\n",
            "</div>\n",
            "\n",
            "æœ‰äº›æ‰€è°“æŠ€æœ¯é«˜æ‰‹å·ç§°ç»™é‡è¦çš„å¼€æºè½¯ä»¶è´¡çŒ®è¿‡ä»£ç ï¼Œä½†æ·±æ‰’ä¸€ä¸‹å¯ä»¥å‘ç°ï¼Œåªæ˜¯æ”¹äº†æ”¹æ–‡æ¡£è€Œå·²ï¼Œå†™æµ‹è¯•ç”¨ä¾‹çš„éƒ½ç®—æ·±å…¥äº†ã€‚\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "jp-MarkdownHeadingCollapsed": true
         },
         "source": [
            "## æ€ä¹ˆè´¡çŒ®\n",
            "\n",
            "### å‡†å¤‡\n",
            "\n",
            "1. åªèƒ½ç”¨è‹±è¯­\n",
            "2. ç†Ÿè¯»è´¡çŒ®æŒ‡å¯¼ï¼ˆ[LangChain Python ç‰ˆ](https://github.com/hwchase17/langchain/blob/master/.github/CONTRIBUTING.md)ã€[LangChain JS ç‰ˆ](https://github.com/hwchase17/langchainjs/blob/main/CONTRIBUTING.md)ã€[Semantic Kernel](https://github.com/microsoft/semantic-kernel/blob/main/CONTRIBUTING.md)ï¼‰ï¼Œäº†è§£è¯¦ç»†çš„æµç¨‹ã€è¦æ±‚ã€æ³¨æ„äº‹é¡¹ç­‰\n",
            "\n",
            "å¦‚æœä»¥ä¸Šä¸¤æ­¥ä¸èƒ½åšæŒï¼Œæ­¤å¤„å¯ä»¥æ”¾å¼ƒï¼Œä¹Ÿå¿…é¡»æ”¾å¼ƒäº†â€¦â€¦\n",
            "\n",
            "### é€‰é¢˜\n",
            "\n",
            "1. å®Œå–„æ–‡æ¡£ã€åšè¯­è¨€ç¿»è¯‘æ˜¯ä¸é”™çš„èµ·æ‰‹å¼ï¼Œå¯ä»¥ä½“éªŒä¸‹å…¨æµç¨‹ã€‚ç¬¦åˆæµç¨‹å¾ˆé‡è¦ï¼Œä¸ç„¶å¯èƒ½åå€’æ˜¯ç»™äººå®¶æ·»éº»çƒ¦\n",
            "2. ä» issues é‡Œé¢æ‰¾ä¸€ä¸ªä½ æ„Ÿå…´è¶£çš„ï¼Œæˆ–è€…è‡ªå·±æä¸€ä¸ªï¼Œæœ€å¥½æ˜¯èƒ½è§£å†³å®é™…é—®é¢˜çš„ï¼Œè¯¢é—®é¡¹ç›®ç»´æŠ¤äººè‡ªå·±æ˜¯å¦å¯ä»¥æ¥è¿™ä¸ª issueã€‚å¾—åˆ°åŒæ„ï¼Œå°±å¯ä»¥åŠ¨æ‰‹äº†\n",
            "3. å›½äº§å¤§æ¨¡å‹é£èµ·äº‘æ¶Œï¼ŒLangChain å’Œ SK ä¹Ÿéœ€è¦æ”¯æŒæ›´å¤šçš„å¤§æ¨¡å‹ï¼Œå¯ä»¥ä»è¿™æ–¹é¢å…¥æ‰‹\n",
            "\n",
            "### åŠ¨æ‰‹\n",
            "\n",
            "è¿‡ç¨‹ä¸­è‚¯å®šä¼šé‡åˆ°å¾ˆå¤šé—®é¢˜ã€‚æŠ€æœ¯ä¸Šçš„ï¼Œè§„èŒƒä¸Šçš„ï¼Œè¯­è¨€ä¸Šçš„ç­‰ç­‰ã€‚æ”»å…‹è¿™äº›é—®é¢˜ï¼Œæ˜¯å¾ˆå¤§çš„é”»ç‚¼ã€‚\n",
            "\n",
            "ä»£ç è¢«æ¥å—çš„é‚£ä¸€åˆ»ï¼Œæˆå°±æ„Ÿæ˜¯éå¸¸å¼ºçš„ã€‚\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "# æ€»ç»“\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "1. LangChain.js å’Œ LangChain ä¿æŒäº†æ¦‚å¿µä¸€è‡´ï¼ŒåŠŸèƒ½ä¸°å¯Œï¼Œå¾ˆé€‚åˆå‰ç«¯åŒå­¦ä½¿ç”¨\n",
            "2. Semantic Kernel æ¶æ„è®¾è®¡æ›´å¥½ï¼Œæœªæ¥å‘å±•æ½œåŠ›æ›´å¤§ï¼Œå€¼å¾—è·Ÿè¸ªã€å°è¯•\n",
            "3. è¶å®ƒä»¬éƒ½è¿˜ä¸å®Œå–„ï¼Œæ­£æ˜¯å‚ä¸å¼€æºè½¯ä»¶å»ºè®¾çš„å¥½æ—¶æœº\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "jp-MarkdownHeadingCollapsed": true
         },
         "source": [
            "# ä½œä¸š\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "ä¸ºè‡ªå·±é€‰ä¸€ä¸ªä¸»æ”»æ–¹å‘å§ï¼ŒLangChainã€LangChain.js æˆ– Semantic Kernelã€‚ç„¶åç”¨å®ƒæ¥å®Œæˆæ‰€æœ‰ä½œä¸šã€é¡¹ç›®ã€‚\n"
         ]
      }
   ],
   "metadata": {
      "kernelspec": {
         "display_name": "Python 3 (ipykernel)",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.11.6"
      }
   },
   "nbformat": 4,
   "nbformat_minor": 4
}
